Page Number,Summary
1,"The document discusses conversational user interface (CUI) and its key component, natural language understanding (NLU). It explains how NLU enables CUI to interpret and respond to user input in a more human-like manner. The document also mentions that NLU is a growing field and highlights its importance in creating effective and user-friendly CUIs. The author of the document is Dr. Aobo Wang and the document is copyrighted by NUS."
2,"The second page of the document 'CUI-Day2 v.4.0.pdf' outlines the agenda for the day, which includes a focus on Task-Oriented CUI and Agentic Frameworks. The key topics to be covered are intent detection, slot filling, dialog management, and response generation. The document also provides an introduction to Agentic Frameworks, defining them and discussing their use cases."
3,"Page 3 of 'CUI-Day2 v.4.0.pdf' discusses the different types of conversational user interfaces (CUIs), including specialist bots and generalist bots. Specialist bots are designed for specific tasks, while generalist bots are more versatile and can handle a variety of tasks. CUIs can also be categorized as task-oriented or non-task-oriented, depending on their purpose. Overall, there are various types of CUIs that serve different functions and cater to different user needs."
4,"Page 4 of the document discusses the reasons for and against using Conversational User Interfaces (CUI). The main arguments for using CUI include the potential for increased efficiency, improved user experience, and the growing popularity of voice assistants. However, there are also concerns about privacy and security, limitations in understanding complex queries, and the need for specialized programming skills. Ultimately, the decision to use CUI should be based on the specific needs and goals of the organization."
5,"The task-oriented CUI workflow is a process for creating conversational user interfaces (CUIs) that are focused on completing specific tasks. This workflow involves identifying user goals, designing a conversation flow, and building the CUI using natural language processing and machine learning techniques. It also involves testing and refining the CUI to ensure its effectiveness and usability. The goal of this workflow is to create CUIs that are intuitive, efficient, and user-friendly for completing tasks."
6,"The document discusses the concept of task-oriented conversational user interfaces (CUIs) and why they are not based on language model learning (LLM). Task-oriented CUIs are designed to assist users in completing specific tasks through natural language interactions. They differ from LLM-based CUIs, which are focused on understanding and responding to open-ended conversations. The document argues that LLM-based CUIs may not be suitable for certain tasks, such as completing transactions or providing specific information, as they may struggle with understanding and responding accurately. Task-oriented CUIs, on the other hand, are more effective for these types of tasks as they are designed with a specific goal in mind."
7,"The core architecture of DeepDial, a conversational AI platform, consists of three main components: the user interface, the natural language understanding module, and the dialogue management module. The user interface allows for interaction between the user and the system, while the natural language understanding module processes the user's input and extracts relevant information. The dialogue management module then uses this information to generate a response to the user. DeepDial also includes a knowledge base and a learning module to improve its performance over time. Additionally, the platform supports integration with external APIs for accessing external data sources."
8,"Skills Kit (ASK) is a popular framework for developing skills for Amazon Alexa

The Alexa Skills Kit (ASK) is a widely used framework for creating skills for Amazon Alexa. It allows developers to easily build and deploy custom voice interactions for the Alexa platform."
9,"is a platform for building conversational interfaces

Google Dialogflow is a platform designed for creating conversational interfaces. It follows a task-oriented workflow, meaning it focuses on accomplishing specific tasks or goals through conversation. This platform is user-friendly and offers various tools and features for developing and testing chatbots. It also allows for integration with other platforms and services, making it a versatile option for building conversational interfaces."
10,"The RASA architecture is a task-oriented conversational user interface (CUI) workflow developed by NUS. It is designed to facilitate interactions between users and computer systems through natural language processing. The workflow involves three main components: the user interface, the dialogue manager, and the natural language understanding module. The user interface allows users to input their requests, which are then processed by the dialogue manager to determine the appropriate response. The natural language understanding module helps to interpret the user's input and extract relevant information. This architecture aims to improve the efficiency and effectiveness of CUI interactions."
11,"Page 11 of the document 'CUI-Day2 v.4.0.pdf' discusses natural language understanding (NLU), which is the process of understanding and interpreting human language by computers. NLU involves various techniques such as parsing, semantic analysis, and machine learning to extract meaning from text or speech. It is a crucial component of conversational user interfaces (CUIs) and is used in applications like chatbots, virtual assistants, and voice recognition systems. NLU is constantly evolving and improving, and its accuracy is dependent on the quality of the data and algorithms used."
12,"This section discusses the components of a chatbot, including language understanding, multi-level intent identification, and agents routing. Language understanding involves the ability to interpret and respond to user inputs in a conversational manner. Multi-level intent identification refers to the process of categorizing user intents into different levels to improve accuracy. Agents routing helps to direct user requests to the appropriate agent or department. Additionally, the chatbot may utilize a knowledge base and frequently asked questions (FAQ) to provide helpful responses. Overall, a chatbot is a computer program designed to simulate conversation with human users and assist with tasks or provide information."
13,"Page 13 of the document 'CUI-Day2 v.4.0.pdf' discusses natural language understanding (NLU) for task completion. NLU is the ability of a computer system to understand and interpret human language. It is an essential component of conversational user interfaces (CUIs) and is used to process user inputs and generate appropriate responses. NLU involves several steps, such as tokenization, part-of-speech tagging, and named entity recognition, to extract meaning from user inputs. It also involves the use of machine learning and deep learning techniques to improve accuracy and handle variations in language. NLU is crucial for effective communication in CUIs and is constantly evolving to better understand human language."
14,"The document discusses the process of understanding requests in AI before the implementation of agentic AI. It mentions key elements such as question-word, command-word, intent-word, location-word, and time-word, which are used to understand the request. Examples of requests include asking about the weather in Seattle or London, or requesting the current temperature. The concept of intent detection and slot filling is also introduced, with sample utterances provided."
15,"Page 15 of the document discusses intent detection, which is the process of identifying the purpose or goal behind a user's input in a conversational system. This is an important component of natural language understanding and is often achieved through machine learning techniques. Intent detection involves identifying the intent behind the user's input and mapping it to a specific action or response. It is crucial for creating effective and efficient conversational systems."
16,"The NLU pipeline used by NUS for self-service spoken language understanding consists of both deterministic and stochastic components. The deterministic component uses FST to compile sample utterances, while the stochastic component utilizes machine learning models for predicting entities, slots, and intent. This approach is based on the architecture proposed in the paper ""Just ASK"" and is designed for extensibility."
17,"The document discusses deterministic intent detection, which involves using simplified finite state transducers that are generalized by named entity recognition. Dictionaries are also used to enrich the knowledge base for more accurate intent detection."
18,"The NLU pipeline for building an architecture for extensible self-service spoken language understanding includes both deterministic and stochastic approaches. Deterministic methods use finite state transducers to compile sample utterances, while stochastic methods involve machine learning models for predicting entities, slots, and intents. This combination allows for more accurate and flexible language understanding."
19,"The document discusses the concept of stochastic intent detection, which involves using machine learning models to classify user intents. This allows for better organization of knowledge and can be used in various applications such as weather forecasting and travel recommendations. The example given is a user asking about the weather in Seattle, which would be classified as the intent ""WeatherForecast."""
20,"The document discusses the features that can be used for short text classification, which includes unigram and bigram features, term frequency, TFIDF, POS tags, dependency parsing, and knowledge-based patterns. These features are useful for analyzing short utterances, as they can provide information about the language used and the relationships between words. They can also help in identifying patterns and improving the accuracy of classification."
21,"• “(please) (*) (thanks) (*)” → polite-Pattern


The document discusses utterances and their characteristics, highlighting that they are typically short. It mentions two types of knowledge-based patterns: declarative knowledge, which involves binary features, and social behavior knowledge, which involves word count features. Examples of these patterns are given, such as the seeking-pattern, which includes phrases like ""I want"" or ""we like,"" and the polite-pattern, which includes phrases like ""please"" and ""thanks."" These patterns can help identify the intent behind an utterance."
22,"Page 22 discusses the use of Convolutional Neural Networks (CNN) and Bidirectional Long Short-Term Memory (BiLSTM) models in natural language processing. CNNs are commonly used for text classification tasks, while BiLSTMs are more suitable for sequential data such as language translation. Both models have their own strengths and can be combined to improve performance in various NLP tasks."
23,"Page 23 of the document discusses the use of Bi-Directional Recurrent Neural Networks (RNN) for classification tasks. These networks, specifically the Contextual BiLSTM, allow for the consideration of both past and future context in the classification process, making them more effective than traditional RNNs. The document also mentions the use of word embeddings, which are numerical representations of words, to improve the performance of these networks. Overall, Bi-Directional RNNs, particularly the Contextual BiLSTM, are a useful tool for classification tasks due to their ability to incorporate context and the use of word embeddings."
24,"Page 24 discusses the natural language understanding (NLU) pipeline for slot filling, which is a process in which a system identifies and extracts specific pieces of information from user input. The pipeline includes several steps, such as tokenization, part-of-speech tagging, and named entity recognition, to analyze the input and determine the relevant slots to be filled. This process is essential for building self-service spoken language understanding systems, as seen in the ""Just ASK"" architecture."
25,"Page 25 discusses the concept of ""slots filling"" in natural language processing, which refers to the process of identifying and extracting specific information from a user's input. This is a crucial step in building conversational agents and chatbots, as it allows them to understand and respond to user requests accurately. The document highlights the importance of understanding the context and intent behind a user's input, as well as the use of techniques such as named entity recognition and rule-based systems to extract relevant information. It also mentions the challenges of handling ambiguous or incomplete input and the need for continuous training and improvement of slot filling algorithms."
26,"This page discusses the concept of slots filling, which is a sequence labelling problem where observations and labels are in a sequence. The example given is identifying the location and time in a question about the weather. The labels used are BIO, which stands for Beginning of Entity/Slot, Inside of Entity/Slot, and Outside of Entity/Slot. The example shows the sequence of labels for the question ""what is the weather in London today"" and ""what is the weather in New York."""
27,"The document discusses the use of regular expressions and dictionaries for filling slots in natural language understanding systems. Regular expressions can be used for identifying and extracting specific patterns, such as dates, addresses, and phone numbers. Dictionaries are useful for identifying entities such as locations, names of people and organizations, and domain-specific terms. These tools can help improve the accuracy and efficiency of slot filling in NLU systems."
28,"The document discusses the use of a Bi-LSTM (Bidirectional Long Short-Term Memory) model with a CRF (Conditional Random Field) for text classification. This approach combines the strengths of both models, allowing for better performance in tasks such as named entity recognition and part-of-speech tagging. The model also incorporates word embedding, which maps words to numerical vectors, to further improve performance. Results from experiments show that this approach outperforms traditional methods in text classification tasks."
29,"The document discusses using a combination of Bi-LSTM, CRF, and CNN with word and character embedding for truly end-to-end natural language processing, without the need for feature engineering. This approach has been found to be effective in tasks such as named entity recognition and part-of-speech tagging. It involves using a bidirectional long short-term memory network (Bi-LSTM) to capture contextual information, a conditional random field (CRF) to model the sequence of labels, and a convolutional neural network (CNN) to extract features from both words and characters. This approach has shown promising results and eliminates the need for manual feature engineering."
30,"in NER

This section discusses the use of a bi-directional LSTM model with a CRF layer and CNN layer, incorporating both word and character embeddings. This approach is considered truly end-to-end and does not require manual feature engineering. The results show a significant improvement in named entity recognition (NER)."
31,"Page 31 discusses the use of agentic AI, which refers to AI systems that have the ability to take initiative and make decisions on their own. This type of AI is becoming more prevalent in various industries, such as customer service and healthcare. The website deepdial provides resources for understanding and implementing agentic AI, including a platform for building conversational AI agents. This technology has the potential to greatly improve efficiency and effectiveness in various tasks and industries."
32,", the AI system is designed to act autonomously and make decisions based on its own analysis and understanding of the situation. This can be useful in situations where human intervention is not possible or desirable, such as in emergency response or military operations.

Agentic AI refers to an AI system that is designed to act independently and make decisions based on its own analysis and understanding of a given situation. This type of AI can be beneficial in situations where human intervention is not possible or desirable, such as in emergency response or military operations."
33,"The use of agentic AI in intent detection and slot filling is discussed in this section. This involves using a dictionary, pattern matching, and LLM to identify and fill in slots in a user's query. These techniques help the AI understand the user's intent and provide a more accurate response."
34,"– Natural Language Generation – Response Ranking

The document discusses the agenda for the second day of the CUI workshop, which includes topics such as dialog management, response generation, and natural language generation. The session will cover interaction strategies, error handling, confirmation strategies, dialogue state tracking, dialogue policy, and response ranking. These topics are important for creating effective conversational user interfaces."
35,"The document discusses different interaction strategies in dialogues and who takes the initiative. It notes that the speaker usually takes the initiative by initiating the conversation and setting the topic. However, the listener can also take the initiative by asking questions or making comments. The document emphasizes the importance of mutual understanding and cooperation in dialogues, with both the speaker and listener actively participating and exchanging information. It also mentions the role of turn-taking and how it helps maintain a smooth flow of conversation. Overall, the document highlights the importance of both parties being engaged and taking turns in a dialogue."
36,"The system-directed initiative is a feature that allows users to search and book services and ask questions to navigate the conversation. This results in efficient dialogs, but it may lack flexibility as the user is only able to answer the system's queries. This feature is developed by NUS and is protected by copyright."
37,"The concept of user-directed initiative refers to a system where the user has control and the system responds to their queries in a natural and flexible manner. This approach is designed to minimize the constraints placed on the user and create a more user-friendly experience. However, it is important to note that this user-directed initiative can be faked through the use of a user guide, which may limit the user's true control over the system."
38,"The mixed-initiative strategy in conversational user interfaces allows both the user and the system to take the lead in the conversation. This approach gives users more control and flexibility in navigating the interface, as they can choose when to ask for information or give commands. It also allows the system to proactively provide relevant information or suggestions, making the interaction more efficient and user-friendly. This strategy is commonly used in virtual assistants and chatbots, and can enhance the user experience by creating a more natural and dynamic conversation."
39,"The mixed-initiative strategy in conversational user interfaces allows both the user and the system to take the lead in the conversation. Users can initiate dialogue by asking questions, introducing new topics, or providing overly informative responses. The system must maintain and monitor the conversation history and its own agenda in order to effectively engage in mixed-initiative dialogue."
40,"Error handling and confirmation strategies are important for ensuring the accuracy and reliability of user input in a computer user interface. These strategies involve detecting and handling errors in user input, as well as providing confirmation messages to the user to confirm their actions. Some common error handling strategies include displaying error messages, allowing users to correct their input, and using default values. Confirmation strategies involve providing feedback to the user after an action is performed, such as displaying a success message or asking for confirmation before proceeding with a potentially irreversible action. These strategies help to improve the overall user experience and prevent errors in the interface."
41,"The document discusses error handling and confirmation strategies in the context of user interfaces (UI). It emphasizes the importance of providing clear and concise error messages to users, and suggests using a combination of visual cues and text to convey the error. It also recommends implementing confirmation prompts for critical actions to prevent accidental or irreversible actions. Additionally, the document highlights the importance of considering the user's mental model and designing error handling and confirmation strategies that align with their expectations."
42,"The document discusses error handling and confirmation strategies in conversational user interfaces. It mentions that intents and slots can be uncertain or ambiguous, and errors from automatic speech recognition (ASR) and natural language understanding (NLU) may be passed on. To address this, a confidence score threshold can be set, where scores below the threshold indicate the need for confirmation or rejection. Explicit confirmation can also be used, but this may make the conversation longer."
43,"for users to process and understand

The document discusses the importance of error handling and confirmation strategies in user interfaces. It emphasizes that responses should be concise and clear, avoiding over-informative messages that can confuse users. It also suggests using visual cues and feedback to confirm user actions and prevent errors."
44,"When encountering issues with a product, there are strategies that can be used to improve the customer experience. One strategy is confirmation, where the customer's issue is acknowledged and confirmed to show that their concern is being taken seriously. Another strategy is sentiment analysis, which involves understanding the customer's emotions and addressing them appropriately. If the issue cannot be resolved through automated means, the customer should be able to switch to human assistance for further help. It is important for the system to be able to understand complex and unfamiliar statements from customers in order to provide effective assistance."
45,"Dialog management (DM) is responsible for deciding what to say and do in a conversation with a user. There is no single definition for DM, as it varies depending on the specific tasks involved. However, it plays a crucial role in ensuring user satisfaction. The main tasks of DM include determining interaction strategies, handling errors and confirmation, tracking the dialogue state, and creating a dialogue policy."
46,"Page 46 discusses dialogue management without agentic AI, focusing on the dialogue policy. The dialogue policy is responsible for selecting the next action in a conversation, and it can be rule-based or data-driven. Rule-based policies use pre-defined rules to determine the next action, while data-driven policies use machine learning algorithms to learn from data and make decisions. Hybrid policies combine both approaches. The choice of dialogue policy depends on the complexity of the dialogue and the available data. It is important to continually evaluate and improve the dialogue policy to ensure effective communication with users."
47,"The dialog state tracking (DST) process involves tracking the state of a conversation between a user and a computer system. The output of DST is a representation of the conversation's current state, which can be used to guide the system's responses in subsequent turns. This is referred to as ""cross turn"" DST, as it involves tracking the state across multiple turns in the conversation. This process is important for maintaining context and improving the overall user experience."
48,"Dialog State Tracking (DST) refers to the system's ability to track and represent the state of a conversation with a user. This is achieved through layers of DST, which involve the system's internal representation of the conversation and its belief of what the user wants at each turn. DST is an important component of conversational user interfaces and enables the system to understand and respond to the user's needs and intentions."
49,"The process of dialog status tracking involves defining the state of the conversation based on domain knowledge or natural language understanding, and attaching appropriate actions to each state. This can be done through handcrafted approaches, where the state and actions are manually defined, or through NLU techniques. By tracking the dialog status, a system can better understand the context of a conversation and respond accordingly."
50,"This page discusses handcrafted approaches for building conversational user interfaces (CUIs). One approach is the task-oriented scenario, which involves designing a conversation flow that guides the user towards completing a specific task. Another approach is AskNext, which uses a search-based method to suggest the next action for the user based on their current state. These approaches can be visualized using handcrafted states diagrams."
51,"restaurant-searching

The document discusses handcrafted approaches for the restaurant searching scenario. It introduces AskNext Search, a deep learning-based conversational agent that can assist users in finding restaurants. The agent uses a combination of natural language processing and machine learning techniques to understand user queries and provide relevant restaurant recommendations. It also incorporates user preferences and context to personalize the recommendations. The document provides a link to the website where AskNext Search can be accessed."
52,"The document discusses handcrafted approaches for conversational user interfaces (CUIs), which involve creating specific actions for different types of tasks. These actions can be divided into three categories: task-independent behaviours such as error correction and confirmation, task-specific behaviours such as search and booking, and task interface behaviours such as prompt selection. These handcrafted approaches are often used in CUI development to improve the overall user experience."
53,"The handcrafted approach to conversational user interfaces (CUIs) is efficient and accurate, making it suitable for narrow domain problems. However, it is important to avoid trying to make the CUI seem overly intelligent. This approach can be challenging as it is difficult to anticipate every possible flow of the conversation. It also requires effort to refine and tune the dialog strategies. Additionally, handcrafted approaches are not easily transferable to new domains."
54,The statistical approach to research is data-driven and offers better scalability. It involves using probability distribution to analyze and interpret data. This approach is recommended for research projects and can be further explored on the website deepdial.
55,"The recent research topic of statistical approaches for natural language understanding (NLU) and dialogue state tracking (DST) is focused on data-driven methods that can adapt to new domains, scale better with more data, and improve the probability distribution. These approaches heavily rely on the quality and coverage of labeled data, which can be time-consuming to collect. More information about these approaches can be found at https://sites.google.com/view/deepdial/."
56,The document discusses the use of neural networks (NN) for dialogue state tracking (DST). DST is an important component of dialogue systems that helps track the progress and context of a conversation. The use of NN for DST has shown promising results in improving the accuracy and efficiency of dialogue systems. The website https://sites.google.com/view/deepdial/ provides resources and information on implementing NN for DST.
57,"This page discusses statistical approaches for natural language understanding (NLU) with dialogue state tracking (DST). The approach involves predefined action types, slots, and values, such as FoodType and PriceRange, to help the system understand user requests. The example given is a user looking for good pizza, with options for different types of food and price ranges. The joint NLU with DST allows for a more accurate understanding of user intent and preferences."
58,"The statistical approach discussed on page 58 involves using a word-based RNN (recurrent neural network) called wordvec to analyze words in a sentence. The example given shows the calculation of values for the words ""What,"" ""part,"" and ""Indian,"" which are then used to predict the word ""Indian."""
59,"• use statistical methods to learn the probability of slot-value pairs being associated with certain intents

The document discusses the use of statistical approaches in natural language processing, specifically delexicalisation. This involves replacing specific slots and values in a sentence with generic labels, allowing for the construction of semantic dictionaries. Statistical methods are then used to learn the probability of certain slot-value pairs being associated with particular intents. This approach can help improve the accuracy and efficiency of natural language processing systems."
60,"A statistical approach called Word-Based RNN with Delexicalisation is used to predict the likelihood of different values for a specific slot, such as ""Food."" This approach involves using one RNN for each slot and taking into account the most recent user input and machine dialog act. It predicts the likelihood for all pairs of value and slot."
61,"The document discusses statistical approaches for natural language understanding (NLU) and dialogue state tracking (DST). These approaches eliminate the need for feature engineering and delexicalisation with lexicon resources. Instead, they use pre-trained word vectors and have been shown to match the performance of delexicalisation-based models. This makes them better-suited for scaling in situations where creating domain-specific lexicons would be difficult. A specific example is the use of a data-driven word vector for word ""U"" and context ""[REDACTED_PHONE]"" in a neural belief tracker."
62,"Dialogue State Tracking

The Neural Belief Tracker is a statistical approach used for dialogue state tracking. It utilizes neural networks to learn from data and make predictions about the dialogue state. It is able to handle large and complex dialogue systems, and has shown promising results in various applications such as restaurant reservation and travel planning. However, it also has limitations, such as the need for large amounts of training data and the difficulty in interpreting the learned representations. Further research is needed to improve the performance and interpretability of this approach."
63,The Neural Belief Tracker is a statistical approach used in dialogue systems to represent utterances. It is based on neural networks and can handle multiple utterances at once. It uses a combination of word embeddings and recurrent neural networks to represent the utterances. This approach has shown promising results in dialogue state tracking and can be used in various applications such as chatbots and virtual assistants.
64,"The page discusses a dataset for dialogue state tracking (DST) that is available for download. The dataset was created by the National University of Singapore (NUS) and contains dialogue data from various sources, including movie scripts and restaurant reservation conversations. It is intended for use in training and evaluating DST models. The page provides a link to access the dataset and gives instructions on how to use it."
65,"The dialog policy is a key component of a conversational system that determines what the system should do next based on the current conversation context. It involves the use of rules, machine learning, and reinforcement learning to generate appropriate responses and actions. The policy can be designed to prioritize certain goals or actions, and can be evaluated through metrics such as task completion rate and user satisfaction. The design and evaluation of a dialog policy is crucial for creating a successful conversational system."
66,"The dialogue policy is an important aspect of research in the field of conversational user interfaces. There are three main approaches to developing a dialogue policy: rule-based, frame-based, and statistical. Rule-based policies use predefined rules to determine the system's response, while frame-based policies use a set of frames to represent the dialogue context. Statistical approaches use machine learning techniques to learn the best response based on past interactions. The website deepdial provides resources for researchers interested in exploring dialogue policy."
67,"The document discusses handcrafted approaches in the context of a restaurant searching scenario. It mentions a tool called AskNext Search, which is a deep learning-based conversational agent designed to assist users in finding restaurants. The tool utilizes a combination of natural language processing and machine learning techniques to understand user queries and provide relevant recommendations. The document also provides a link to access the tool."
68,"The document discusses the use of statistical approaches to predict the next state or action in a data-driven manner. This involves encoding the state or action with numbers. The example given is predicting the next action in a dialogue system, where the state is represented by the type of question being asked, the search term, and the location, and the action is the rating given by the user. This approach is further explained on the website https://sites.google.com/view/deepdial/."
69,"The document discusses a statistical approach for classification based on encoding observations after natural language understanding (NLU). It presents an example of a conversation between a customer and a restaurant, where the customer's order is encoded as ""two Chicken Pizza."" The approach uses a threshold to determine if the observation is above or below it, with any unknown observations falling below the threshold."
70,"The document discusses a statistical approach to classification based on encoding. This approach involves predicting the next system response after each user turn. An example is given where the action for S2 is predicted to be ""Welcome"" after the user's turn of ""I want two Chicken Pizza."" The action is labeled as 1."
71,"Schemes

The document discusses statistical approaches for classifying data based on encoding schemes. These approaches involve using statistical methods to analyze and interpret the data, such as frequency analysis and correlation analysis. The document also mentions the importance of selecting appropriate encoding schemes for the data being analyzed, as different schemes may yield different results. Additionally, it highlights the need for proper data preprocessing and feature selection to improve classification accuracy. Overall, the document emphasizes the importance of using statistical approaches and carefully selecting encoding schemes for accurate data classification."
72,"The document discusses statistical approaches for classification, specifically focusing on encoding previous action items and current states. This method involves using previous action items as features and the current state as the target variable for classification. This approach can be used in various applications, such as predicting stock prices or identifying fraudulent transactions. It is important to carefully select features and consider the balance between overfitting and underfitting when using this approach."
73,"Page 73 discusses the use of Agentic AI in dialog management, specifically in a restaurant searching scenario. The tool used for this is AskNext Search, which utilizes rule-based logic. This allows for more efficient and accurate responses to user inquiries. The document is copyrighted by NUS and all rights are reserved."
74,"The key points on response generation for interacting with users include using natural language, providing clear and concise responses, acknowledging the user's input, and using appropriate tone and language. It is important to avoid robotic or scripted responses and to personalize the interaction as much as possible. Additionally, it is important to be aware of cultural and social norms when generating responses. It is also recommended to provide helpful and informative responses, rather than just acknowledging the user's input."
75,"Page 75 discusses response generation in conversational user interfaces (CUIs). It explains that response generation involves generating appropriate and relevant responses to user inputs in a conversational manner. The key points include the importance of natural language processing (NLP) and machine learning in response generation, the use of templates and rules for generating responses, and the challenges of maintaining consistency and avoiding repetitive responses. It also mentions the potential for incorporating emotions and personality into responses to enhance the user experience. Overall, response generation is crucial in creating a smooth and natural conversation between users and CUIs."
76,"Page 76 discusses response generation in Conversational User Interfaces (CUIs). It explains the importance of generating human-like responses and the challenges that come with it. It also covers the use of Natural Language Processing (NLP) and machine learning techniques to improve response generation. The document mentions the different types of responses, such as scripted, templated, and generative, and how they can be used in different scenarios. It also discusses the role of context and personalization in generating effective responses. Additionally, it touches upon the use of sentiment analysis and emotion detection in response generation. Finally, the document emphasizes the need for continuous testing and improvement in response generation to enhance the user experience."
77,"Page 77 discusses response generation in conversational user interfaces (CUIs). It highlights the importance of generating appropriate and relevant responses to user inputs in order to maintain a natural and effective conversation. The key points include the use of natural language processing and machine learning techniques to generate responses, the need for human supervision and feedback in the training process, and the potential challenges and limitations in response generation. It also mentions the importance of considering context and personalization in response generation for a more personalized and human-like interaction."
78,"The agenda for this section includes a discussion on task-oriented conversational user interfaces (CUI), which involves intent detection, slots filling, dialog management, and response generation. The concept of Agentic AI is also introduced, along with its definition, use cases, and frameworks."
79,"Behavior

Agentic behavior is characterized by individuals acting in line with the expectations and demands of a higher authority, without questioning or taking responsibility for their actions. This behavior is often seen in situations where individuals feel a sense of obligation or fear towards the authority figure. It can also be influenced by societal norms and cultural values that prioritize obedience and deference to authority. Agentic behavior can have negative consequences, such as individuals engaging in unethical or harmful actions under the influence of authority. It is important for individuals to critically evaluate and question authority in order to avoid blindly following orders and potentially causing harm. 

Agentic behavior is when individuals comply with the demands of a higher authority without questioning or taking responsibility for their actions. This can be influenced by a sense"
80,"Agentic AI systems are designed to act autonomously and make decisions on behalf of humans, using advanced algorithms and data analysis. These systems can be used in various fields such as finance, healthcare, and transportation, and have the potential to greatly improve efficiency and accuracy. However, there are concerns about the ethical implications of agentic AI, as it may lead to loss of human control and accountability. It is important for developers and regulators to consider these ethical concerns and implement safeguards to ensure responsible use of agentic AI systems."
81,"The document discusses different types of agentic systems, which are computer systems that can act autonomously and make decisions without human intervention. The four main types are reactive systems, goal-based systems, utility-based systems, and learning systems. Reactive systems simply react to stimuli in their environment, while goal-based systems have a specific objective they work towards. Utility-based systems consider the potential outcomes of different actions before making a decision, and learning systems use data to improve their decision-making abilities over time. These agentic systems have various applications in fields such as robotics, artificial intelligence, and autonomous vehicles."
82,"The architecture of agentic AI systems involves a combination of cognitive and physical components. The cognitive components include perception, reasoning, and decision-making processes, while the physical components include sensors, actuators, and effectors. These systems are designed to interact with their environment and make decisions based on their goals and objectives. They can also adapt and learn from their experiences to improve their performance. The architecture of agentic AI systems is constantly evolving and can be customized for different applications and tasks."
83,"Page 83 discusses the concept of ""agentic"" and how it relates to the field of communication. Agentic refers to the ability to take action and make decisions in a purposeful manner. This is important in communication because it allows individuals to actively engage in interactions and achieve their goals. Agentic communication involves being assertive, confident, and goal-oriented. It also involves being aware of one's own needs and being able to effectively express them. Agentic communication can be learned and improved through self-reflection and practice."
84,"The Agentic AI Frameworks are a set of principles and guidelines for developing AI systems that are accountable, transparent, ethical, and human-centric. These frameworks aim to ensure that AI systems are designed and implemented in a responsible manner, with consideration for the impact on individuals and society as a whole. The principles include incorporating human values, promoting transparency and explainability, and establishing mechanisms for accountability and oversight. The frameworks also emphasize the importance of ongoing evaluation and improvement of AI systems, as well as collaboration and communication between different stakeholders. Overall, the Agentic AI Frameworks provide a comprehensive approach to developing and deploying AI systems that prioritize human well-being and ethical considerations."
85,"CrewAI is a software that uses a flow system to organize its functions. The @start() function signals the beginning of the flow, while the def generate_city(self) function generates a city. The @listen(generate_city) function listens for the generate_city function and triggers the def generate_fun_fact(self, random_city) function, which generates a random fun fact about the city. These functions allow for efficient and organized execution of tasks in the CrewAI software."
86,"The document discusses the use of AutoGen, a tool developed by NUS, for automating the generation of agents within a team. AutoGen uses a RoundRobin algorithm to assign agents to a chain of tasks, allowing for efficient distribution of workload. This feature is particularly useful for large teams with complex tasks."
87,":

The LongGraph tool is a visual analytics platform that helps users explore and analyze large, complex datasets. It uses a combination of interactive visualizations and machine learning algorithms to identify patterns and relationships within the data. Users can interact with the visualizations to gain insights and make discoveries, and can also upload their own data for analysis. The tool is designed to be user-friendly and flexible, allowing for customization and collaboration among multiple users. It has been used in various research projects and has shown promising results in identifying hidden patterns and trends in data."
88,"Page 88 of the document 'CUI-Day2 v.4.0.pdf' discusses the LongGraph, a tool used for visualizing the structure and connections of long documents. Developed by researchers at the National University of Singapore, LongGraph utilizes a graph-based approach to represent the relationships between different sections and concepts within a document. It allows users to navigate through a document in a more efficient and intuitive way, making it easier to understand the overall content and connections between different ideas. The tool has potential applications in various fields, including education, research, and information organization. A video demonstration of LongGraph is also available on YouTube."
89,"The article discusses four AI agent frameworks: OpenAI Swarm, LangGraph, AutoGen, and CrewAI. These frameworks have different levels of flexibility and complexity, and it is important to choose the right one for a specific task. The article emphasizes the ""no free lunch"" concept, meaning that there is no one framework that works best for all situations. The article also mentions the importance of scalability and the potential limitations of using a single framework for all tasks."
90,"The referenced papers and websites focus on neural network-based approaches for spoken dialogue systems, specifically in the areas of language generation, dialogue state tracking, and end-to-end trainable systems. These approaches use techniques such as recurrent neural networks and data-driven dialogue state tracking to improve the performance of dialogue systems. Some of the content in the slides is adapted from a dialogue tutorial given by Jianfeng Gao and Vivian Chen."
