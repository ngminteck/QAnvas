Page,Summary
Page 1,Accelerating Digital ExcellenceCopyright National University of Singapore Agenda• Day 3• 1: Speech processing basics• 2: Speech recognition (Speech-to-text)• 3: Case studies: Integrating speech recognition and NLP
Page 2,3
Page 3,4
Page 4,5
Page 5,6
Page 6,7
Page 7,8
Page 8,9
Page 9,10
Page 10,11
Page 11,12
Page 12,13
Page 13,14
Page 14,15
Page 15,16
Page 16,17
Page 17,18
Page 18,environmental information as well- Indoor / Outdoor- Quiet / Noisy19 . 19 .
Page 19,20
Page 20,21
Page 21,22
Page 22,23
Page 23,24
Page 24,25
Page 25,26
Page 26,27
Page 27,28
Page 28,29
Page 29,30
Page 30,31
Page 31,32
Page 32,33
Page 33,34
Page 34,You can askChatGPT (or Gemini inColab) code segmentsfor specific operations.35 .
Page 35,36
Page 36,37
Page 37,38
Page 38,39
Page 39,40
Page 40,41
Page 41,ASR is a process of automatically converting speech into writtentext . it is the first step in processing speech and does not interpretmeaning at this stage .
Page 42,http://languagelog.ldc.upenn.edu/nll/?p=60956)Reverberation and overlapping audio sources as well.
Page 43,44
Page 44,45
Page 45,"Accelerating Digital ExcellenceCopyright National University of Singapore ASR in Recent Years 46 Source: D. Jurafsky and J.H. Martin, Speech and Language Processing."
Page 46,47
Page 47,Dynabench: Rethinking Benchmarking in NLPSpeech recognitionHandwriting recognitionReadingcomprehensionReading comprehensionLanguage understandingSource: Kielaet al.
Page 48,Accelerating Digital ExcellenceCopyright National University of Singapore Evolution of ASR methods 49 Source: Labellerr.
Page 49,50
Page 50,51
Page 51,52
Page 52,53
Page 53,evaluate how likely a given word sequence is correct . evaluate the likelihood that a speech signal corresponds to a sequence of sound units .
Page 54,55
Page 55,56
Page 56,57
Page 57,58
Page 58,59
Page 59,60
Page 60,61
Page 61,62
Page 62,63
Page 63,64
Page 64,65
Page 65,66
Page 66,67
Page 67,68
Page 68,69
Page 69,70
Page 70,71
Page 71,or Transformer Transducer 72
Page 72,or Transformer Transducer73
Page 73,74
Page 74,https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452 75
Page 75,76
Page 76,PART 4. EMERGING ADVANCED SPEECH PROCESSING 77 . PART 3. PART 5. PART 6. PART 7. PART 8. PART 9. PART 10. PART 11. PART 2.
Page 77,training data is adapted to a wide range of downstream tasks . training data can be used to build specialized applications .
Page 78,79
Page 79,"Whisper Model• Trained on 680k hours of multilingual and multitask superviseddata• Three tasks: speech recognition, speech translation, and language recognition• #model parameters: 39M, 74M, 244M,"
Page 80,Accelerating Digital ExcellenceCopyright National University of Singapore Wav2Vec2.0: Self Supervised Learning 81 .
Page 81,82
Page 82,83
Page 83,84
Page 84,85
Page 85,86
Page 86,Accelerating Digital ExcellenceCopyright National University of Singapore ChatGPT: LLM with Speech Capabilities 87.
Page 87,88
Page 88,Integrate external LMs with E2E models via shallow fusion for domain adaptation89 . fusion is a technique that can be used to combine external and internal LM models for domain adaption .
Page 89,Letter-based or byte pair encoding (BPE) based acoustic modeling is effective . letter-based modeling is also viable if large training datasets are available .
Page 90,http://huggingface.co/blog/fine-tune-whisper• Espnet: end-to-end speech processing• Kaldi: HMM-DNN acoustic modeling• jon
Page 91,LM training with SRILM• https://cmusphinx.github.io/wiki/tutoriallmadvanced/• Morph n-gram model• http://research.spa.
Page 92,93
Page 93,94
Page 94,character error rate (CER) or Syllable Error Rate (SER) may be used for some languages .
Page 95,96
Page 96,97
Page 97,98
Page 98,99
Page 99,100
Page 100,101
Page 101,102
Page 102,103
Page 103,104
Page 104,105
Page 105,106
Page 106,CMU Sphinx (works offline)• Google Speech Recognition• Google Cloud Speech API• Wit.ai• Microsoft Bing Voice Recognition• Houndify API• IBM Speech to Text• Snowboy Hotword Detection
Page 107,Python Speech Recognition is an open-source project at the National University of Singapore . website: https://pypi.org/project/SpeechRecognition/108/ .
Page 108,Topic 3: Case studies: Integrating speech recognition and NLP solutions109 . Topic 4: Topic 5: Topic 6: Topic 7: Topic 8: Topic 9: Topic 10: Topic 2: Topic 3 : Topic 1: Topic
Page 109,Accelerating Digital ExcellenceCopyright National University of Singapore Integrating speech recognition and NLP Possible applications:1. Voice Search2. Customer Service Analysis3. Speech Translation4. Meeting Transcription and SummaryPunctuation and capitalization restoration
Page 110,111 is the process of determining who spoke when in an audio recording . goal: segment and cluster the audio so that all segments from the same speaker are grouped together .
Page 111,112
Page 112,113
Page 113,114
Page 114,text output from ASR often needs to be transformed or normalized to match the input format expected by an existing text-based search system . real me => Realme• Redmi => Redme
Page 115,Accelerating Digital ExcellenceCopyright National University of Singapore Quality Control of Customer Service• Customer and agent sentiment (from text and speech)• Text sentiment analysis• Non-talk time• Talk speed• Interruptions – Still challenging!
Page 116,machine translation enables users to watch foreign videos in their own language . https://www.mdpi.com/2076-3417/13/15/8900
Page 117,https://medium.com/free-code-camp/a-history-of-machine-translation-from-the-cold-war-to-deep-learning-f1d335ce8b
Page 118,Accelerating Digital ExcellenceCopyright National University of Singapore Evolution of Machine Translation Methods 119-119 .
Page 119,higher scores represent better MT performances . higher BLEU scores may decreases as sentence lengths increase . n-grams of machine-translated sentences are compared to those of human sentences .
Page 120,Catastrophic Errors in MT• Generation of profanity.• Mistranslation of proper names.• Generating of violent or inciting content.
Page 121,misrecognized words lead to inaccurate or nonsensical translations . MT systems for low-resource languages often exhibit poor accuracy . live or near-live translation requires low latency .
Page 122,Accelerating Digital ExcellenceCopyright National University of Singapore Live or Near-live Translation• Real time translation: start while sentence is spoken• Synchronization: start when sentence is sung• Real-time translation: begin while
Page 123,"R. Zhang et al, Dynamic Sentence Boundary Detection for Simultaneous Translation ."
Page 124,EMNLP 2022: Balancing Source and Target at Information Level for Simultaneous Machine Translation .
Page 125,126
Page 126,127
Page 127,128
Page 128,Translation of pronouns may require co-reference 129 . the university of singapur is a leader in the field of digital translation .
Page 129,Accelerating Digital ExcellenceCopyright National University of Singapore Meeting Transcription Otter.ai . .
Page 130,"Accelerating Digital ExcellenceCopyright National University of Singapore Meeting Summarization Evaluation metrics for summarization: BLEU, ROUGE"
Page 131,misrecognized words lead to awkward or inaccurate summary . identifying and differentiating speakers correctly is crucial for attributing statements accurately .
Page 132,133
Page 133,134
Page 134,135
Page 135,136
Page 136,137
Page 137,key performance metrics to be considered:• Token Per Second (TPS) = (input tokens + output tokens) / Total Turnaround Time • Time To First Token (TTFT)• Consider quantization
Page 138,Accelerating Digital ExcellenceCopyright National University of Singapore Gartner Hype Cycle 139 - Accelerated Digital Excellence .
Page 139,www.iss.nus.edu.sgThank you for your interest in iss_nus .
Overall Summary,"acoustic modeling is the process of automatically converting speech into writtentext . higher scores represent better MT performances, limiting their real-world utility . high-quality speech recognition is a key component of a successful machine translation project ."
