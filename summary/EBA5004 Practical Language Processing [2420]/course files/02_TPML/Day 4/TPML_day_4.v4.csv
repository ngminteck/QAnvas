Page,Summary
Page 1,TEXT PROCESSING USING MACHINE LEARNING MODULE 4 Dr. Aobo Wang isswan@nus.edu.sg
Page 2,LLaMA’s family Model Tuning with Prompts/Instructions Workshop MOE Extra topics to discuss Reasoning RLMS . Day 4 Trend
Page 3,Copyright National University of Singapore. All Rights Reserved 3 . Fine-tuning with Instructions .
Page 4,Copyright National University of Singapore. All Rights Reserved 4/5/2014 . Copyright: national university of singapur .
Page 5,Bloomberg GPT: Model Supervised Fine-Tuning Bloomberg gPT: model supervised fine-tuning .
Page 6,Fine-Tuning is a Model Supervised fine-tuning technique . the model is supervised by a computer program .
Page 7,"LLaMA’s family • Alpacas, llamas, and llama’s ."
Page 8,LLaMA’s family
Page 9,Prompt Tuning
Page 10,"Prompt Tuning prefers larger models to smaller ones . prompt engineering is not good enough to be considered good enough . if you're looking for a faster, more efficient way to do things, try pro"
Page 11,All Rights Reserved . Adapters • Prefix-tuning • Low-rank Adaptation .
Page 12,Adapters 2019 2021 Adapter-Efficient Fine-tuning Copyright National University of Singapore.
Page 13,All Rights Reserved 1 4 • Adapters: Adapter-Efficient Fine-tuning Copyright National University of Singapore.
Page 14,Copyright National University of Singapore. All Rights Reserved 1 5 • Prefix-tuning .
Page 15,• Prefix Tuning (a) Copyright National University of Singapore. All Rights Reserved 16 prompt vectors .
Page 16,"Usually it refers to the Prompt Tuning (b) . if you want to make a 'prompt' tune, you can use the prompt tuning function ."
Page 17,• Prefix Tuning (b) Copyright National University of Singapore. All Rights Reserved 18 soft prompt with Embedding.
Page 18,All Rights Reserved 19 LSTM Tuning (c) . Copyright National University of Singapore.
Page 19,Prefix Fine-tuning in CV 2022 • Visual Prompt Tuning (VPT) 2022
Page 20,Prefix Fine-tuning in CV 2022; Context Optimization (CoOp) 2022 .
Page 21,"Low-rank (LORA) metrics are low-rank metrics . LORA metrics are based on a combination of a number of factors, such as the degree of difficulty and the degree to which they are measured ."
Page 22,Low-rank Adaptation (LORA) is a low-rank adaptation technique . it's used to fine-tune a wide range of acoustic instruments . LORA's low-
Page 23,• Low-rank Adaptation (LORA) (low-rank adaptation): low-ranking ad hoc .
Page 24,LLaMA’s family
Page 25,performance gap between LLaMA 2 70B and GPT-4 and PaLM-2-L is still large .
Page 26,LLaMA2
Page 27,LLaMA2
Page 28,deepseek-ai/DeepSeek-MoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models . moe GitHub - moe.org -
Page 29,LLaMA’s family Parameter-Efficient Fine-tuning Workshop MOE Extra topics to discuss RL & Reasoning . Day 4 Trending Topics
Page 30,"“linearly” increase exponentially, according to a new study by the National University of Singapore . all rights reserved ."
Page 31,Emergent Phenomena Knowledge driven logic driven . Emergent phenomeena . Knowledge driven Logic Driven .
Page 32,"ability is emergent if it is not present in smaller models but is present in larger models . ability is emerging if the ability isn't present in small models, but is in larger ones ."
Page 33,floating point operations are a comprehensive measure of a model's scale . it considers not only parameters but also factors like data volume and training epochs .
Page 34,Copyright National University of Singapore. All Rights Reserved 3 5 5 5 6 6 7 7 7 8 7 7 9 7 9 9 9 10 10 10 11 11 11 12 11 12 12 12 13 13 13 14 14 14 13 14 13 13
Page 35,Emergent Phenomena
Page 36,"Emergent Phenomena 13B is very basic, not likely to deal with logic heavy tasks accurately 40B - 50B could be possible Better to start from 70B ."
Page 37,"Emergent Phenomena 13B is very basic, not likely to deal with logic heavy tasks accurately 40B - 50B could be possible Better to start from 70B ."
Page 38,Emergent by Grokking ?
Page 39,Impossible Triangle Retention
Page 40,RetNet 41
Page 41,RetNet
Page 42,https://medium.com/ai-fusion-labs/retentive-networks-retnet-explained-the-much-awaited-transformers-killer-is-he
Page 43,Evaluation Impressing on GAOKAO Benchmark Outperforming LLM with less and smaller model . Using an incomplete and inaccurate evaluation method: Swap the order of the scenes .
Page 44,Evaluation
Page 45,Evaluation
Page 46,hallucinations • Faithfulness: Input content • Factualness: Common sense . Hallucination: common sense; common sense: lucination .
Page 47,Intrinsic Hallucination: conflicting with the input content Extrinsic hallucinations: creating unknown facts*
Page 48,hallucination • Causes (Data): Wrong Memory (link) Training data quality:
Page 49,hallucination • Causes (Data): Deduplicating training data makes language models better .
Page 50,Hallucination - Causes (Prompts): Be more specific when ask question Role Play Query/Instruct + Background Content Prompt Engineering .
Page 51,Hallucination • Causes (Sampling) BeamSeach instead of Beamseach .
Page 52,Hallucination • Causes (Sampling) factual-nucleus sampling algorithm (link)
Page 53,"Domain Shift Exposure bias: training and the generation procedure mismatch Minimum Risk Training (MRT), which avoids exposure bias, can mitigate this ."
Page 54,BLEU/ROUGH score against the reference . compare with the results from search engine/Wikipedia .
Page 55,hallucination • How to detect: By External Refence Compare with the results from search engine/Wikipedia Transformer Memory Network models .
Page 56,hallucination can be detected by using a 'reference free method' . the method is based on the By External Refence Reference Free method .
Page 57,Hallucination • How to detect (Faithfulness) Refence-Free methods By Question generation (FEQA)
Page 58,natural language inference (NLI) tries to detect factuality in generation . -> Putin is U.S. president .
Page 59,natural language inference (NLI): hallucination is a form of lucidation . it can be detected by using a number of different methods .
Page 60,hallucination: how to detect (faithfulness) Refence-Free methods By Factualness Classification Metric Train a detection model Post Classification .
Page 61,Hallucination • Other Tricks: (Faithfulness) • Sketch to content (Two-Stage Generation) • Controllable grounded response generation (Inductive Attention)
Page 62,LLaMA’s family Parameter-Efficient Fine-tuning Workshop MOE Extra topics to discuss RL & Reasoning . Day 4 Trending Topics
Page 63,Reinforcement learning
Page 64,RL Framework Reinforcement learning
Page 65,RF with DL
Page 66,"RF with DL Example Environment: (forcing +1 or -1 movement of the card) Reward: Score Function [seconds keeping up] State: L,R,UP,DOWN Agent: 2-layer"
Page 67,Reinforcement learning Limited Action Spaces
Page 68,softmax: 'select a word by softmax . 'softmax' is a neoclassical .
Page 69,Reinforcement learning
Page 70,"RL with Human Feedback Proximal Policy Optimization, PPO Policy: generate a sequence of words based on prompt . select a word by softmax from V Observation space : all possible sequences of words"
Page 71,RL with Human Feedback Reinforcement Learning from Human Feedback (Natural Language Processing at UT Austin) - YouTube .
Page 72,"RL with Human Feedback RLHF Instead of RF, use RM Initial LLM, (GPT), 175B Reward Model RM, 6B RM ."
Page 73,generate a sequence of words based on prompt . select a word by softmax from V Observation space .
Page 74,Reasoning
Page 75,this is a replicate of DeepSeek-R1-Zero training on small models with limited data RL for Reasoning 1. SFT for cold start 2.
Page 76,Reasoning
Page 77,https://github.com/NVIDIA/NeMo/blob/main/tutorials/nlp/Multitask_Prompt_and_PTuning.ipynb
Overall Summary,LLaMA’s family Model Tuning with Prompts/Instructions Copyright National University of Singapore. All Rights Reserved 3 1 “linearly” increase exponentially Emergent Phe
