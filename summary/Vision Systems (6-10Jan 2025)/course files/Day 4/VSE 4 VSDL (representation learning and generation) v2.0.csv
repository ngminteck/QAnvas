Page,Summary
Page 1,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore .
Page 2,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] . Feature representation learning (supervised and self-supervised)
Page 3,Feature representation learning: Learn to map from data space to representation space . supervised learning: Use data with (manually) human-annotated labels . target task (downstream task): the actual target application
Page 4,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore . it takes two views of the input batch and minimizes the correlation .
Page 5,the encoder takes an input image with missing regions . the decoder takes this feature representation and produces the missing image content .
Page 6,"a large random subset of image patches (e.g., 75%) is masked out . mask tokens are introduced after the encoder . the full set of encoded patches is processed by a small de"
Page 7,"images rotated by: 0°, 90°, 180°, and 270° . task: Predict which rotation is applied; 4-category classification task . assign a “label” to each rotation"
Page 8,2kk and 2kk + 1 element is a positive pair InfoNCE Loss (Noise- Contrastive Estimation) Each image tries to predict which of other 2NN1 images came from the same original
Page 9,"Embedding zz(2) Input xx Loss gradient gradient Simple contrastive learning of representation (SimCLR) Transform Crop, Color distortions, Gaussian blur Encoder ResNet + MLP head"
Page 10,"input xx Loss Momentum Contrast (MoCo) Transform Crop, Color jittering, Horizontal flip Encoder ResNet Loss InfoNCE = + (1"
Page 11,"Embedding zz(2) Input xx Loss Self-distillation with no labels (DINO) Transform Color jittering, Gaussian blur, Multi-crop Encoder ViT"
Page 12,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore . all rights reserved Page 12 Applications of (self-supervised) feature representation learning .
Page 13,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore . DINO is popular for pre-training ViT models .
Page 14,"a dataset of 400 million (image, text) pairs collected on the internet . CLIP trains an image encoder and a text encoder to maximize the cosine similarity of the image and text embeddings of"
Page 15,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 15 Application 2: Bi-directional multimodal pre- training (CLIP
Page 16,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 16 Application 2: Encoder-decoder multimodal pre-
Page 17,image encoder MAE pre-trained ViT-H/16 Prompt encoder Point The sum of a positional encoding of the point’s location and one of two learned embeddings that indicate if
Page 18,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 18 Application 2: Decoder-only multimodal pre- training (LL
Page 19,"a pre-trained CLIP model Text prompt (designed by users, possible image recognition result) Identify the category of the input test image by selecting the text prompt with the largest similarity ."
Page 20,"S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore . re-identification: Given a photo (face/body), classify among possible"
Page 21,classifier trained from image dataset with annotationInput query image Andrew Ng Annotated image dataset to train the classifier . classifier’s score is based on the image dataset .
Page 22,"image matching The traditional approach for matching images relies on a pipeline: Feature extraction, e.g., color histogram, LBP, HoG, pre-trained CNN or ViT . image matching ("
Page 23,"Feature similarity evaluation For unit vectors xx, yy, we have various pre-defined metrics, which are fully specified without the knowledge of data ."
Page 24,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore .
Page 25,"Siamese neural network is a class of neural network architectures that contain two or more identical subnetworks . ICCV 2015, https://openaccess.thecvf.com/content_iccv_"
Page 26,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 26 Siamese network: Loss function Contrastive Loss
Page 27,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 27 Siamese network: Summary Input query image Apply the Si
Page 28,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All rights reserved Page 28 How about non-human objects?
Page 29,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore .
Page 30,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 30 How about non-human objects?
Page 31,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] . Feature representation learning (supervised and self-supervised)
Page 32,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore .
Page 33,a group of people are chained inside a cave their entire life . they can only see the two- dimensional shadows projected onto a wall in front of them .
Page 34,autoencoder (AE) DecoderEncoder Input Latent Reconstruction 4 4 conv . a latent vector R21 .
Page 35,"latent space can be manipulated using interpolated vector zzcc (between two latent vectors zzaa, zzbb) the interpolation parameterzzc R21 is an interpol"
Page 36,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 36 Taxonomy of generative vision models Generative models in
Page 37,"generator learns to create images from random noise, aiming to mimic the distribution of real images . the mapping (generator) from the latent space to the data space is learned with the regularization (discriminator)"
Page 38,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 38 GAN: Training (D) Generator (G) GG(
Page 39,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore .
Page 40,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 40 GAN: Example An online demo: https://poloclub.
Page 41,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 41 Appendix: Other GAN variants Reference: Generative
Page 42,"the VAE decoder is still trained using a reconstruction loss (e.g., MSE or Binary Cross-Entropy), as in an AE . a distribution loss (KL divergence) is"
Page 43,"Reparameterization trick allows differentiable sampling from a latent distribution by expressing the random latent variable as a deterministic transformation of a noise (i.e., a random number) and the distribution"
Page 44,V[REDACTED_PHONE] National University of Singapore. All rights reserved Page 44 VAE: Distribution loss (KL divergence)pp zz = 1 2pp2 exp xxpp 2 2p2
Page 45,"random latent vectors are sampled from the prior distribution . they are then passed through the decoder, which maps them to the data space, generating new images ."
Page 46,"Q1: Consider a color image (512 512), what is the dimension of the image space? A1: How would an image with random uniform colors appear? A2: Let me generate it. image = torch."
Page 47,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore .
Page 48,"S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 48 DDPM key idea (1) A pre-defined (fixed, non"
Page 49,"a decoder neural network trained with shared parameters in a multi-step reverse process, re-formulating generative modeling into a set of supervised prediction tasks . a random image space is real image space"
Page 50,xxtt is generated as a combination of scaled data and noise . aa2 + bb2 = 1. Controlled noise level tt 1 Why?
Page 51,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore . use model to learn known train . NN 1 tt xx
Page 52,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 52 Appendix If you are curious about how to derive the loss
Page 53,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 53 Model training: Overview Forward process (tt steps) xx0
Page 54,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 54 Model training: Backbone U-Net backbone reference.
Page 55,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 55 Generation (sampling) xx0xxtt1
Page 56,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 56 DDPM: A summary (From the neural network perspective) De
Page 57,Fréchet Inception Distance (FID) evaluates the quality of images generated by generative models . lower FID scores indicate that the generated images are closer in quality and diversity to the real images .
Page 58,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 58 What is next: Other diffusion models Optimization Speed up DDIM
Page 59,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore .
Page 60,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore .
Overall Summary,S-VSE/Building vision systems using deep learning (representation)/V[REDACTED_PHONE] National University of Singapore . All Rights Reserved Page 1 BUILDING VISION SYSTEMS USING DEEP LEARNING (3) REPRESENTATION LEARNing AND GENERATION Dr TIAN Jing [REDACTED_EMAIL] Note: notations and color codes used across multiple slides might be inconsistent .
