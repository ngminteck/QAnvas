Page,Summary
Page 1," The contents of this document may not be reproduced in any form or by any means, without the written permission of ISS, NUS, or other than for the purpose for which it has been supplied ."
Page 2, The National University of Singapore's Cluster Analysis Program uses cluster clustering methods and software tools . The program is presented at the National Institute of Singapore’s Cluster Analysis Centre .
Page 3, Clustering is an unsupervised learning method that seeks to discover natural patterns in data and dividing them into clusters . Smaller clusters are meaningful and useful for understanding complex business problems.
Page 4, The terms ‘clustering’ and ‘classification’ are often used interchangeably . Clustering is grouping observations into some unknown categories . Classification is grouping observed into some known categories . The  aim is to
Page 5, Clustering aims to group data into clusters such that: Observations within a cluster are similar to each other but…   Observations between clusters are dissimilar to others .
Page 6, The World Health Organisation (WHO) would like to identify countries  that would benefit from their Medical Aid Fund . Countries that are “Poor” will be given more funds than countries “Advance” or “Mod
Page 7," The idea behind Clustering is to  find meaningful groupings of                 countries based on the following  characteristics: Literacy Rates, Baby Mortality Rates, Birth Rates, Death Rates, and Birth Rates ."
Page 8, A desirable outcome is the discovery of several clusters of countries such that each cluster has similar characteristics but … … but … ... not all have similar characteristics . Every cluster is distinctly different from each other .
Page 9, Clusters found in the WHO dataset have been clustered in four clusters . The results of the cluster analysis were published at the National University of Singapore .
Page 10," Introduction to Data Mining (Second Edition) Pang-​Ning Tan, Vipin Kumar: How many clusters? Four Clusters? Four clusters? Two clusters? Six clusters ."
Page 11, Clustering algorithms use various distance/similarity measures to develop clusters . The goal of clustering is to minimize the Intra-Cluster distance .
Page 12," Euclidean Distance Measure is default distance measure for K-means . Given two cases i, and j (in the p-dimensional space) the distance is defined by a defined distance defined by j (i) and j"
Page 13, Which pair is ipientclosest to each ipient other? The pair is the closest to each other and the closest they can be .
Page 14," The data value used for clustering is the index of  the ordering- i.e. treated as if it were continuous . Customer Satisfaction:  Poor, Unsatisfactory, Satisfactory, Good, Excellent . The"
Page 15," Types of Clustering Approach: Hierarchical, Agglomerative, Divisive, Partition, K-Means, Density-based, DBSCAN, HDBSCAN and K-Modes ."
Page 16, Singapore's National University of Singapore 16Hierachical Clustering . The team has been working on a new method of clustering in a cluster of cities .
Page 17, Two variants of Hierarchical Clustering have been used in a new book . The book is published by the National University of Singapore .
Page 18, Two basic approaches for generating a hierarchical clustering: Agglomerative and Divisive . Start with the points as individual clusters and merge the closest pair of clusters . This requires defining a notion of cluster proximity .
Page 19," The aim is to find groupings of countries that share similar characteristics in terms of: Literacy, baby Mortality, literacy, baby mortality and baby deaths ."
Page 20," The results of hierarchical clustering is often displayed graphically using a tree-like diagram called a dendrogram, which displays the cluster-subcluster relationship and the order in which the clusters were merged ."
Page 21, How does Agglomerative Clustering work? How does it work? An optimal clustering is defined by aggregator of aggregator clusters .
Page 22," Previously, we learned how to compute distances between objects . In hierarchical clustering, we need to find distances between clusters . The following are some of these methods: Centroid, Single Linkage and Wards ."
Page 23, Inter Cluster Distance Measure Methods . National University of Singapore 23-year-old method of cluster-clustering is published at http://rpubs.com/inayatus/.
Page 24, A dendrogram is a tree diagram   used to illustrate the arrangement of  the clusters. The color display is for 4 clusters. C1: Argentina … Italy; C2: Chile … Vietnam; C3: Bolivia
Page 25, Divisive Clustering Algorithm uses a flat clustering algorithm (e.g. K-means) to split the cluster into 2 clusters . Repeat steps 1-4 until the pool consist only of clusters with a single
Page 26," Once two clusters are merged, it cannot be undone . Dendrogram can be too large to read for thousands of data observations . A single pass through the data may yield poorer results ."
Page 27, National University of Singapore 27K-Means Clustering . 27K is a form of clustering that aims to create clusters of clusters .
Page 28, K-Means clustering is a type of top-down divisive clustering . Requires the user to specify in advance the number of clusters to be formed (k clusters) Data observations are then clustered based on its proximity to a nearest
Page 29, K-means clustering algorithm was created by the National University of Singapore 29-year-old algorithm . The algorithm is based on K number of clusters and the distances between each point and the nearest centroid .
Page 30, The data points will be assigned to the centroid that is nearer . The data point is assigned to nearest centroid .
Page 31, K-Means clustering method has been used in data mining . National University of Singapore's National Institute of Singapore has published a book on data mining techniques .
Page 32," K-means uses the Sum of Squared Error (SSE) as the objective function . For each point, the error is the distance to the nearest cluster center . The SSE is expected to improve with each iteration of K"
Page 33," National University of Singapore 33.5-2 -1.5 -1 -0.5 0 0.5 1 1.5, 2.5 and 3.5 ."
Page 34," Pang-​Ning Tan, Vipin Kumar and Vipil Kumar write 34-page Introduction to Data Mining (Second Edition)"
Page 35," Pang-​Ning Tan, Vipin Kumar and Vipil Kumar write National University of Singapore's 35-page Introduction to Data Mining (Second Edition)"
Page 36, Some solutions to Initial Centroids Problem: Select points that are farthest away from current centroids or select the first point at random or take the centroid of all points at random . Some solutions: Multiple runs with different sets
Page 37, K-means is a seeding technique by Arthur and Vassilvitskii (2007) Found to improve quality of local optimum and lower runtime . Computationally more costly than random initialization .
Page 38," The K-Means algorithm is guaranteed to converge to a result. However, the result may be a local optimum . Clustering is a heuristic method and therefore much experimentation is needed to achieve the desired outcome ."
Page 39, The median is computed in each single dimension in the Manhattan-distance problem of the k-medians problem . K-prototypes algorithm combines k-modes and k-means .
Page 40, National University of Singapore 40Density-Based Spatial Clustering of Applications with Noise (DBSCAN) DBSCAN is based on a 40D density--based spatial clustering of applications with noise .
Page 41, K-Means is a Centroid-based clustering algorithm . Data are assigned to the nearest centroid to form new clusters . It is highly sensitive to outliers and can sometimes sometimes cause undesirable effects .
Page 42," In DBSCAN, there are no centroids, and clusters are formed by linking nearby points to one another . There is also the concept of noise points in the DBSCA algorithm . These  are points that do"
Page 43, Density-based clustering is a clustering method that identifies distinctive clusters in the data . It is based on the idea that a cluster in data space is a contiguous region of high point density .
Page 44, Core point is a point with a specified MinPts within its Eps . Core points are points that are at the interior of a cluster . Noise point is any point that is not a core point or a border point .
Page 45, A core point is core because it has MinPts within its Eps neighborhood . A border point is a border point because it is within the Eps neighborhood of A but doesn't satisfy it . A noise point is NOT within an Eps neighborhood
Page 46, The DBSCAN algorithm can be abstracted into the following steps: Find the points in the ε (epsilon) neighborhood of every point . Assign each non-core point to a nearby cluster if the cluster is an
Page 47, National University of Singapore 47DBSCAN Animation Animation . DBSCAN Clustering Algorithm in Machine Learning - KDnuggets .
Page 48, DBSCAN does not require you to specify the number of clusters . Can find arbitrarily shaped clusters even if the cluster is completely surrounded by a different cluster . Able to detect noise and is robust to outliers .
Page 49, National University of Singapore 49Kmeans vs DBSCAN . 49KMeans vs. DBSC is a Singapore university . DBS CAN is a national university of Singapore .
Page 50," There is no automatic way to determine the MinPts value . For 2-dimensional data, use DBSCAN’s default value of MinPt = 4 . The larger the data set, the larger the value should be"
Page 51, The MinPts can be used to estimate the average distances between each point and its k nearest neighbors . The average k-distances are then plotted in ascending order on a graph .
Page 52, National University of Singapore 52-year-old study was published by the National Institute of Singapore . The study looked at the Validity of Clustering Models in a cluster of clusters of clusters .
Page 53, Clusters are meant to uncover patterns and provide insights for decision-making . Cluster Validation procedures are procedures used to evaluate the goodness of clustering . This is important because clustering is an unsupervised learning method .
Page 54, National University of Singapore 54: Evaluating the Validity of Cluster Models . The study was conducted by the University of Singapore . The findings were published at the National Institute of Singapore .
Page 55, The Hopkins statistic (Lawson and Jurs 1990) is used to assess the clustering  of a data set by measuring the probability that a given data set is generated by a uniform data distribution .
Page 56, Internal cluster validation uses the internal information of the clustering process to evaluate the goodness of a clustering structure without reference to external information . External cluster validation measures the extent to which cluster labels match externally supplied class labels . Relative cluster validation is
Page 57," The K-Means algorithm is somewhat naïve because it clusters the data into k clusters, even if k is not the right number of clusters to use . In general, there is no accurate method to find the exact value of K"
Page 58, The basic idea behind k-means clustering consists of defining clusters so that the total intra-cluster (within cluster) variation is minimized .
Page 59," The Elbow method is the best way to find k, k-means . The WSS will get smaller as you increase the number of clusters of k clusters ."
Page 60," A good clustering solution is composed of well-separated  cluster centroids . Large dispersion values are desired . The higher the SSB, the more  separated the derived clusters ."
Page 61, The Silhouette coefficient can vary between -1 (worst) and +1 (best) A score of 0 indicates data lying between clusters . Most tools report that a silhouette score of > 0.3 is acceptable .
Page 62, The Silhouette coefficient tends to fluctuate with the number of K clusters . It rarely makes sense  to choose K=2 as it will not be meaningful .
Page 63, Individual Cluster Silhouette Analysis was conducted by the National University of Singapore . The study was conducted in conjunction with a cluster of clusters of individual clusters of silhouettes .
Page 64, Using PCA plots are only meaningful if the variance explained is significantly high (>65%) PCA plot is only meaningful for the variance explanation .
Page 65, Boxplots are used to show the distribution of each variable for each cluster . You will want the data distributions . to exhibit significant differences for  the .majority of the variables .
Page 66," If a single cluster contains majority of the data (i.e. dominates), it could imply the need for further clustering . If there are very small clusters, it could mean that they represent outliers. This should warrant further"
Page 67, Model validation is particularly important for cluster analysis because it is an unsupervised learning technique . Cross-validation is a popularly used method . Randomly split the original data into two groups and perform cluster analysis on each group .
Page 68, Second method is to split randomly the clustering data set into two parts . Development and Validation ( 50:50) Perform cluster analysis on development sample only . Create cluster profiles . Validate the results on the validation sample using development sample
Page 69, Singapore's National University of Singapore has published a book on cluster clusters . The book is published by the National Institute of Singapore . It is based on a cluster of clusters to develop market personas .
Page 70, Understanding of the clusters through proﬁling is required to take full advantage of them in subsequent marketing activities . Profiling requires working closely with the subject matter expert .
Page 71," Each cluster must be useful for marketing, sales or promotion . Clusters must offer convenience –  it is easier to focus on fewer clusters than clusters ."
Page 72, Cluster profiling helps us to gain a contextual understanding of the  meaning of each cluster . Cluster profiling requires the use of domain knowledge and judgement . Criteria to guide cluster profiling: Look for distinguishing characteristics .
Page 73, Cluster Literacy Baby Birth Death Size: C1 96.40 11.36 14.36 - 9.20 9.2 5.00C2 85.78 36.78 - 36.34 24.78 6 9.
Page 74," Cluster 1 (High Literacy, Low Baby-Mortality, Birth, Death rates) appears to be fit the profile of today’s advance countries . Cluster 4 (Low Literacy) fits profile of poorer countries ."
Page 75, Can labels be assigned intuitively? Can you assign labels to babies? The National University of Singapore study is based on a cluster of infants born in Singapore .
Page 76, Can clusters lead to some action? We can also see  that actions can be appropriately applied to each cluster . The National University of Singapore's labelling suggests clusters can lead to meaningful action .
Page 77," Cluster Analysis is versatile and can be used in many business problems, says National University of Singapore 77 . Cluster Analysis can help identify groups of policy holders with high average claim claims, fraud detection, and health & bioinformatics ."
Page 78," Cluster analysis assumes that all customers within a segment are similar, leading to generalized marketing strategies that may not be as effective . Cluster analysis provides insights into customer behavior, preferences, and characteristics, helping businesses make informed decisions and develop target"
Page 79," National University of Singapore 79-Demo, Workshop, Exercises, is a workshop at the university's National Institute of Science and Technology ."
Page 80, National University of Singapore 80 per cent of Singapore students are Singaporeans . The students are students at the university in Singapore . They are students of the National University Singapore .
Overall Summary, Clustering is an unsupervised learning method that seeks to discover natural patterns in data and dividing them into clusters . Smaller clusters are meaningful and useful for understanding complex business problems . The World Health Organisation (WHO) would like to
