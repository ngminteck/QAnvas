Page,Summary
Page 1,"the contents contained in this document may not be reproduced without the written permission of ISS, NUS, other than for the purpose for which it has been supplied ."
Page 2,Introduction to Cluster Analysis 2. Application of Cluster Analysis 3. Types of Clustering Methods 4. How to Validate the Created Clusters 5. How to Profile Clusters 6. Limitations of cluster analysis 7. Demonstration of clustering using
Page 3,clustering is an unsupervised learning method that seeks to discover natural patterns in data and dividing them into clusters . smaller clusters are meaningful and useful for understanding complex business problems .
Page 4,clustering is grouping observations into some known categories . target category (e.g. fraud) is given upfront . aim is to find homogenous subsets of observations .
Page 5,clustering aims to group data into clusters such that: • Observations within a cluster are similar to each other but... • DissimilarClustering Algorithms are similar .
Page 6,"the world health organisation (WHO) would like to identify countries that would benefit from their medical aid fund . it would be desirable to have countries grouped into: 'Advance, Moderate' or 'Poor"
Page 7,SN Country Literacy Baby Mort Birth Rate Death Rate 1 Argentina [REDACTED_PHONE] . san francisco (singapore) is a grouping of countries based on their characteristics .
Page 8,each cluster has similar characteristics but each cluster is distinct from each other . the cluster is distinctly different from the other san francisco .
Page 9,the clusters were found in the WHO dataset Results of the Cluster Analysis with 4 clusters . $0 $$$ $ $$ $$ .
Page 10,National University of Singapore 10 Six Clusters Different ways of clustering a same set of points Introduction to Data Mining (Second Edition)
Page 11,clustering algorithms use distance/similarity measures to develop clusters . a similarity measure is used to decide whether data points are far apart or near to each other .
Page 12,"Euclidean Distance is default distance measure for K-means . given two cases i, and j the distance is defined by [REDACTED_PHONE](...)() ."
Page 13,non-Standardized standardized Standardized . non-standardized standardization . . Non-Statemented Standardized Standardised Standardized standardised standardized standard .
Page 14,"the data value used for clustering is the index of the ordering . SN Satisfaction Job 1 Unsatisfactory lawyer 2 Excellent doctor 3 Poor lawyer Dist(Unsatisfy, Excellent) = 3"
Page 15,"national university of Singapore 15 Types of Clustering Approach . K-modes, k-prototypes, density-based clustering . expectedation-maximization algorithm ."
Page 16,National University of Singapore 16 Hierachical Clustering . Copyright . national university of singapore 16 hierachical clustering.
Page 17,two variants of Hierarchical Clustering are available at the national university of Singapore . this is the second variant of hierarchical clustering .
Page 18,"this requires defining a notion of cluster proximity . Agglomerative: • start with the points as individual clusters and, at each step, merge the closest pair of clusters ."
Page 19,national university of Singapore 19 Example Objective is to find groupings of countries that share similar characteristics in terms of: • Literacy • Baby Mortality • Births • Deaths Cluster 1 Cluster 3 Cluster 2 Cluster 4 Cluster 4 cluster 4 Cluster
Page 20,"the results of hierarchical clustering is often displayed graphically using a tree-like diagram called a dendrogram, which displays both the cluster-subcluster relationships and the order in which the clusters were merged"
Page 21,iterations 5 Clusters Argentina Australia USA Greece Italy Greece Italy Australia USA Argentina . Greece Italy 4 Clusters 3 Clusters 2 Clusters 1 Cluster Iteration#1: Australia + USA Iterations#3: [Australia +
Page 22,"we learned how to compute distances between clusters . in hierarchical clustering, we need to find distance between objects ."
Page 23,national university of Singapore 23 Inter Cluster Distance Measure Methods https://rpubs.com/inayatus/hierarchical-clustering.
Page 24,a dendrogram is a tree diagram used to illustrate the arrangement of the clusters . read from left to right 1. Greece + Italy .
Page 25,1 cluster consisting of N records • Step 1: Apply a flat clustering algorithm (e.g. K-means) to split the cluster into 2 clusters . Step 4: Repeat steps 1-4 until the pool consist
Page 26,it is hard to decide on the number of clusters to retain . a single pass through the data may yield poorer results .
Page 27,National University of Singapore 27 K-Means Clustering is a group of K-means from the national university of Singapore .
Page 28,k-means clustering is a type of top-down divisive clustering . it requires the user to specify in advance the number of clusters to be formed .
Page 29,k data point is seed points (initial centroids) for each cluster that has lost or gained a data point . re-assign data points to the nearest centroid to form new clusters.
Page 30,"centroid Xi will be assigned to nearest centroid nearer d1 d2 xi C2C1 min(d1, d2)"
Page 31,"Introduction to Data Mining (Second Edition) Introduction to data mining . Pang- Ning Tan, Vipin Kumar Kumar, jinda et al., are the authors of this paper ."
Page 32,x is a data point in cluster Ci and mi is the centroid (mean) for cluster Ci . dist() is usually the Euclidean distance measure .
Page 33,-[REDACTED_PHONE] x y Iteration 1 Centroids from the previous example Take a new set of Centroids .
Page 34,"National University of Singapore 34 Case [REDACTED_PHONE] x y Iteration, x, y, iteration and 6 Introduction to Data Mining ."
Page 35,"Introduction to Data Mining (Second Edition) Introduction to data mining . Pang- Ning Tan, Vipin Kumar Kumar, jinda hueber ."
Page 36,"multiple runs with different sets of initial random centroids . choose the set with the least SSE . tendency to include outliers . for each successive initial centroid, select the centroid ."
Page 37,idea is to spread the k initial cluster centroids far from each other . more costly than random initialization but subsequent k-means often converge faster .
Page 38,the K-Means algorithm is guaranteed to converge to a result . but the result may be a local optimum (i.e. not necessarily the best possible)
Page 39,the medoid of a cluster is defined as the object in the cluster . the median is computed in each single dimension in the Manhattan-distance formulation of k-medians problem .
Page 40,National University of Singapore 40 Density-Based Spatial Clustering of Applications with Noise (DBSCAN) Copyright .
Page 41,K-Means is a Centroid-based clustering algorithm . data are assigned to the nearest centroid to form new clusters .
Page 42,"in the DBSCAN algorithm, there are no centroids and clusters are formed by linking nearby points to one another . there is also the concept of noise points ."
Page 43,a cluster in data space is a contiguous region of high point density . low density regions are separated from other clusters .
Page 44,point p is a point with a specified MinPts within its Eps . Noise point is any point that is not a core point or a border point .
Page 45,MinPts = 7 A is core because it has Minpts within its Eps neighborhood of B is a border point because it is within the Eps area of A . it doesn’t satisfy MinPtes C
Page 46,DBSCAN algorithm can be abstracted into steps . find the points in the (epsilon) neighborhood of every point . identify the core points with more than minPts neighbors .
Page 47,DBSCAN Animation - KDnuggets https://en.wikipedia.org/wiki/DBSCAN Clustering Algorithm in Machine Learning .
Page 48,"can find arbitrarily shaped cluster even if the cluster is completely surrounded by a different cluster . Con: require sufficient high-density areas, not popular in business ."
Page 49,national university of Singapore 49 Kmeans vs DBSCAN . the san francisco-based university of the u.s. is the third-largest university in the world .
Page 50,"the value of MinPts should be set using domain knowledge and familiarity with the data set . for 2-dimensional data, use DBSCAN’s default value of minPt = 4 . if your data has >"
Page 51,"the minPts can be used to estimate the . we calculate the average distance between each point and its k nearest neighbors . if is too small, a large part of the data will not be"
Page 52,National University of Singapore 52 Evaluating the Validity of Clustering Models . the validity of clustering models is a key factor in a clustering model .
Page 53,clusters are meant to uncover patterns and provide insights for decision making . clusters must be valid in the eyes of the stakeholders .
Page 54,National University of Singapore 54 Evaluating the Validity of Cluster Models Technical Approach . evaluating a validity of cluster models .
Page 55,the Hopkins statistic (Lawson and Jurs 1990) is used to assess the clustering tendency of a data set by measuring the probability that a given data set is generated by a uniform distribution .
Page 56,internal cluster validation: uses internal information of the clustering process to evaluate the goodness of a clustering structure without reference to external information . it can be also used for estimating the number of clusters and the appropriate clustering algorithm without
Page 57,"the K-means algorithm is somewhat nave because it clusters data into k clusters, even if k is not the right number of clusters to use . there is no accurate method to find the"
Page 58,the basic idea behind k-means clustering consists of defining clusters so that the total intra-cluster variation is minimized . a good clustering solution is composed of dense concentration (compactness) around
Page 59,use the Elbow method: 1. run k-means for a range of values e.g. k = [REDACTED_PHONE]. calculate the average WSS for each value ofk 3. Plot a line chart
Page 60,"ci is the centroid of cluster i, c the overall centroid, and N the total cases . the SSB is directly related to the pairwise distances between the centroids ."
Page 61,cluster Silhouette coefficient is a combined measure to assess both the intra-cluster-variation (internal cohesion) and the inter-Cluster- variation (external separation) of a clustering solution
Page 62,"the higher the silhouette coefficient, the better the solution . the optimal number of clusters can be found between 2-10 . you should combine the silhouette analysis with other quantitative or qualitative evaluation methods ."
Page 63,National University of Singapore 63 Individual Cluster Silhouette Analyse of individual clusters of syringes .
Page 64,cluster visualization Using PCA plots PCA characters are only meaningful if the variance explained is significantly high (>65%)
Page 65,"boxplots are used to show the distribution of each variable for every cluster . this plot shows significant differences for baby Mortality rates, birth rates ."
Page 66,"cluster size • Examine the number of clusters and their relative sizes . if a single cluster contains majority of the data (i.e. dominates), it could imply the need for further clustering ."
Page 67,cluster solution validation is particularly important for cluster analysis because it is an unsupervised learning technique . cross-validation is a popularly used method . the cluster centroids dataset (100%) cluster 1 cluster 2 cluster 3 cluster 1
Page 68,second method is to split randomly the clustering data set into two parts . Validate the results on the validation sample using development sample clustering algorithm (which becomes the implementation code)
Page 69,National University of Singapore 69 Evaluating the Validity of Cluster Models Business Approach Profiling clusters to develop market personas .
Page 70,national university of Singapore 70 Understanding cluster solutions through profiling . profiling requires working closely with the subject matter expert .
Page 71,national university of Singapore 71 Finding the best solution Interpretability • Look for distinguishing characteristics of each cluster • Explain each cluster in practical terms • Provide meaningful labels for each cluster Ease of use • Align clusters to your product
Page 72,cluster profiling requires the use of domain knowledge and judgement . can each cluster be easily explained? can labels be assigned intuitively?
Page 73,look for extreme HIGH values Look for extreme LOW values look for Distinguishing Characteristics Look for distinguished characteristics .
Page 74,"cluster Literacy Baby Birth Death Size C[REDACTED_PHONE] C[redACTED] C [REDACTRED_PHone] can each cluster be explained in the business context? cluster 1 (High Literacy, low"
Page 75,can labels be assigned intuitively? Cluster Literacy Baby Birth Death Size C[REDACTED_PHONE] . Label Advanced Moderate Borderline Poor .
Page 76,Cluster Literacy Baby Birth Death Size Label C[REDACTED_PHONE] Advanced no funding moderate small funding ($$) Poor Large Funding ($$$)
Page 77,cluster analysis is versatile and can be used in many business problems across many domains . help marketers discover groups in their customer databases and then use this insight to develop targeted marketing campaigns .
Page 78,"cluster analysis assumes homogeneity within segments, meaning that all customers within a segment are similar . interpreting the meaning and characteristics of each segment can be subjective and challenging . cluster analysis helps businesses identify distinct segments within their customer"
Page 79,"National University of Singapore 79 Demo, Workshop, Exercises, Workshops, and other exercises . the 79-year-old demo was created by the u.s. national university of Singapore."
Page 80,national university of Singapore 80 Thank You! Copyright . the u.s. is the only university in the world to have a copyright.
Overall Summary,"the contents contained in this document may not be reproduced without the written permission of ISS, NUS, other than for the purpose for which it has been supplied . Copyright national University of Singapore 2 Topics 1 Introduction to Cluster Analysis 2. Application of Cluster Analysis 3. Types of Clustering Methods 4. How to Profile Clusters 6. Limitations of cluster analysis 7. Demonstration of clustering using software tools (e.g. Python)"
