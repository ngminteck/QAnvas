Page,Summary
Page 1, Video analytics foundation/V3.1 ¬© 2025 National University of Singapore. All Rights Reserved . Dr TIAN Jingtianjing@nus.edu.sg .
Page 2, The National University of Singapore's video analytics foundation/V3.1 was founded by the National Institute of Technology in Singapore . S-RTAVS/Video analytics foundation is based on the work done by the University of Technology Singapore .
Page 3, Ericsson Mobility Visualizer analyzes mobile devices and video devices . S-RTAVS/Video analytics foundation/V3.1 ¬© 2025 National University of Singapore. All Rights Reserved .
Page 4," Changi Airport pilots a Multi-Signal Surveillance Platform which combines audio with video analytics to monitor security incidents . The platform will reduce reliance on security  power, patrolling tasks and costs ."
Page 5, Facial expressions of applicants are also analyzed to determine their willingness to repay the loans . The facial recognition system is used to verify the identity of applicants automatically .
Page 6, Motivation: Multimodal deception ¬†detection¬†needed to be able to bring micro-lending millions of dollars left-out .
Page 7," V-F: given audio clip of a voice and two or more face images/videos, select the face image/video that corresponds to the voice . F-V: given an image or video of a face, determine the corresponding"
Page 8," S-RTAVS/Video analytics foundation/V3.1 ¬© 2025 National University of Singapore . Key video sensing tasks: Processing, Analytics, Compression and Compression ."
Page 9," Each frame of the video stream is analyzed as soon as it is captured and alarms are generated whenever pre-defined triggers are encountered . When used in forensic mode (post-event), analysis software can be used to search through recorded video for"
Page 10, Real-time in the perceptual sense is used mainly to describe the interaction between a human and a computer device for a near instantaneous response of an input by a human user . The result of processing appears effectively ‚Äòinstantaneously‚Äô
Page 11, S-RTAVS/Video analytics foundation/V3.1 ¬© 2025 National University of Singapore. All Rights Reserved .
Page 12, A video is a sequence of frames captured over time . Data (intensity) ùêº is a function of space (ùë•) and time (time) frame resolution: Dimension of each frame . S-RTAVS
Page 13, Video analytics foundation/V3.1 ¬© 2025 National University of Singapore. S-RTAVS/Video analytics foundation . All Rights Reserved .
Page 14, S-RTAVS/Video analytics foundation/V3.1 ¬© 2025 National University of Singapore. All Rights Reserved .
Page 15, The motion vector describes the 2D displacement between the reference image and the other target image . You also can set right image as target and  the left image as reference .
Page 16," Researchers from the National University of Singapore have developed a frame-based and region-based motion-based frame . The frame is divided into regions and regions, such as regions, with each region represented by an object with consistent motion . The"
Page 17," Each image has a size of 10 √ó.8 pixels, each block has a . size of 3 √ó 3 pixels . The block center in current frame (6, 9) is the best matched block center ."
Page 18," Block-based motion feature (2) Searching strategy: Full (slow) search; Sub-optimal (fast) search, e.g.,  three-step search ."
Page 19," Block-based motion feature (3) Each block has a size of 3 √ó 3 pixels . Interpolated left image: 20 √ó 16, Right image: 10 √ó 8 ."
Page 20, Optical flow is the apparent motion of brightness patterns in image . Estimate image motion at each pixel location to obtain optical flow .
Page 21, The image motion of a small patch changes gradually over time . The image movement of a patch is smoothly smoothly regulated over the time . Brightness constancy in a small region remains the same .
Page 22, Optimistic flow calculation (1) gives us 25 equations at 25 pixel locations . We take Taylor series expansion of the image intensity . Assume a small-block of neighboring pixels have similar or even the same (or the pixel location)
Page 23," If we  use a 5 √ó 5 window centered at the pixel  that gives us 25 equations . We need to assume the pixel‚Äôs neighbors have the same (ùë¢, ¬†ùë£) as the pixel"
Page 24," An iterative image registration technique with an application to stereo vision, IJCAI 1981 . The resulting results are based on a re-estimate of optical flow for the  original  ¬†original ùêºÔøΩ"
Page 25," When: Can we differentiate optical flow due to camera motion, lighting, lighting change, object motion? [No] Where: Which part of the optical flow vector cannot be determined from images? (No) When/where optical flow"
Page 26," FlowNetSimple: Stack two sequentially adjacent input images together and feedthem into the network . FlowNetCorr: First produce representations of two images separately, and then combine them together in the ‚Äòcorrelation layer‚Äô ("
Page 27," FlowNet: Learning Optical Flow with Convolutional Networks, ICCV 2015, . FlowNet is a supervised learning for optical flow with convolutional networks ."
Page 28," Self-supervised learning for optical flow is a fully convolutional network, consisting of a contracting part and an expanding part . The contracting part is a stack of convolutionsal layers and the expanding part is  a chain ."
Page 29, Usages of motion features include identifying objects based on motion cues . Recognizing events and activities based on the movements of objects and events .
Page 30, The National University of Singapore's video analytics foundation/V3.1 was founded by the National Institute of Technology in Singapore . S-RTAVS/Video analytics foundation is based on the work done by the University of Technology Singapore .
Page 31, The S-RTAVS/Video analytics foundation/V3.1 ¬© 2025 National University of Singapore. All Rights Reserved .
Page 32, S-RTAVS/Video analytics foundation/V3.1 ¬© 2025 National University of Singapore. All Rights Reserved .
Page 33," Tracker initialization: We need to define the initial state of the target by either drawing a bounding box or (automatically) detecting an object of interest (say, human, car, etc) A module holding the object representation:"
Page 34, S-RTAVS/Video analytics foundation/V3.1 ¬© 2025 National University of Singapore. All Rights Reserved .
Page 35, Template matching is simple color similarity based template matching . The function slides through the image   ùêº   and compares the patch of size  ¬†ùë§ ¬†against the object template ùëá 
Page 36, Template matching is simple cross correlation based template matching . The function compares the patch of size   ùë§ ¬†against the object template ¬†using the specified method and stores the comparison result .
Page 37, Template matching is not robust to illumination change . Learn an optimized filter based on a set of templates not a single template (see next slide)
Page 38, Minimum output sum of squared error filter (MOSSE) filter minimizes the sum of error between the actual output of the correlation and the desired output . Kernelized Correlation Filters (KCF) further introduce regularization into the
Page 39," Researchers from the National University of Singapore used the filter to create a synthetic response map . The filter is based on a correlation filter using MOSSE, KCF and KCF ."
Page 40, CNN-based tracker: GOTURN uses Deep Regression Networks . The network‚Äôs output consists of the coordinates of the top and bottom right corners of the bounding box .
Page 41," CNN-based tracker: SiamFC . It requires offline annotated data . The position of the maximum score relative to the center of the score map, multiplied by the stride of the network, gives the displacement of the target from frame"
Page 42, Transformer tracking (named TransT) is a Siamese-like feature extraction backbone . Attention-based fusion mechanism and classification and regression head are discussed .
Page 43, Transformer-based tracker: TrackerVit .Reference: Joint Feature Learning and Relation Modeling for Tracking: A One-Stream Framework .
Page 44, S-RTAVS/Video analytics foundation/V3.1 ¬© 2025 National University of Singapore. All Rights Reserved .
Page 45," Multiple object tracking to be a association problem, instead of a tracking problem . Simple online and Realtime Tracking with a Deep Association Metric, ICIP 2017 ."
Page 46, The object positions are defined by their bounding box . The position of objects is determined by the position of each object in the current or previous frame .
Page 47, The location similarity between the detected object bounding box in current. current.frame with predicted position of the . previous.frame based on historical trajectory .Apply motion model to formulate the movement of objects . The goal is to predict the most
Page 48, The appearance similarity is the appearance similarity between the detected object bounding box in the current frame and the previous frame . Techniques in single object tracking like cross correlation and SiamFC can be used here .
Page 49," The pairwise match score between objects in two consecutive frames is a pairwise pairwise score . The score is based on position, motion, appearance, position, position and distance ."
Page 50, The trackers will handle object tracking in an online mode . There is no ImageNet dataset in the object tracking domain . Speed is extremely important requirement for real-time tracker .
Page 51, S-RTAVS/Video analytics foundation/V3.1 ¬© 2025 National University of Singapore. All Rights Reserved .
Page 52," Dr TIAN Jing: ""Dr Tianjing@nus.edu.sg"" S-RTAVS/Video analytics foundation/V3.1 ¬© 2025 National University of Singapore ."
Overall Summary," Analysing video data modelling, and object tracking in the video. Analytics for Analytics for Business Intelligence, and . Analytics for super-concealment, super-resolution tracking and . Applications for . applications for video analytics for ."
