Page,Summary
Page 1,AUDIO AND SPEECH ANALYTICS Dr. Gary Leung [REDACTED_EMAIL] Page 1 .
Page 2,2025 National University of Singapore. All Rights Reserved Page [REDACTED_PHONE] .
Page 3,"2025 National University of Singapore. All Rights Reserved Module objective Module: Audio and speech analytics Knowledge and understanding • Understand the fundamentals of audio signal processing, feature extraction and representation for audio and speech analysis Key skills • Design, build"
Page 4,2025 National University of Singapore. All Rights Reserved • Day 1 • 1. Introduction • 2. Audio Signal Processing Basics • 3. Sound Event Detection and Localization • 4. Audio Fingerprinting • 5. Voice Activity Detect
Page 5,"2025 National University of Singapore. All Rights Reserved Major reference Page 5 . T. Virtanen, M. Plumbley, and D. Ellis, ""Computational analysis of sound scenes and events"""
Page 6,audio Speech Music Automatic Speech Recognition (ASR) Virtual Assistants Music Search Surveillance Environmental Monitoring Recommendation Objective: Extract high-level descriptions from raw audio signals (sounds) using either signal analysis to extract features and
Page 7,2025 National University of Singapore. All Rights Reserved Applications 1. Emotion-aware dialogs 2. Urban sound monitoring 3. How to pick a good watermelon? Knock the melon with your phone!
Page 8,"sound (physics): a travelling vibration (wave) through a medium (e.g. air) transfers energy (particle to particle) until ""perceived"" by our ears."
Page 9,the interval between two successive discrete samples is the sampling period (Ts) we use the sampling frequency (fs = 1/Ts ) as the attribute that describes the sampling process .
Page 10,"2025 National University of Singapore. All Rights Reserved Audio signal Page 10 Sampling resolution (quantization): Represent each real number, x(n) of the sequence of samples with an approximation from"
Page 11,2025 National University of Singapore. All Rights Reserved A Analog input signal A Audio signal (1) time Page 11 .
Page 12,2025 National University of Singapore. All Rights Reserved Filtering A B Analog input signal A B time time Audio signal (2) Page 12 .
Page 13,2025 National University of Singapore. All Rights Reserved Filtering A B Analog input signal C clock A B C time time Audio signal (3) Page 13 .
Page 14,Filtering Sampling A B D Analog input signal C clock A B C time time time Audio signal (4) Page 14 .
Page 15,2025 National University of Singapore. All Rights Reserved Filtering Sampling Quantizer A B D E Analog input signal C clock A B C D E [REDACTED_PHONE] time time Audio signal
Page 16,Filtering Sampling Quantizer A B D E Analog input signal Encoder C F clock A B C D E F [REDACTED_PHONE]-bit sign & 3-bit amplitude magnitude) time
Page 17,analog A B D E G Analog input signal Encoder C F clock A B C D E F G [REDACTED_PHONE] time time time Audio signal (7) Page 17
Page 18,analog Filtering A B D E G H Analog input signal Analog output signal Encoder C F clock A B C D E F G H [REDACTED_PHONE] time time time audio signal (8) Page 18
Page 19,16-bit PCM is the basic method of digital representation of audio signals . non-linear coding: A-law and -law logarithmic encoding schemes use only 256 levels (8- bit
Page 20,"2025 National University of Singapore. All Rights Reserved Audio file formats • Popular audio formats • Wav: Developed by Microsoft and IBM. Native format: PCM, Uncompressed lossless • MP3: A lossy"
Page 21,the microphone quality • Environmental quality: ambient noise level • Proper setting of the recording level • Too low: clipping (signal value exceeds maximum) Page 21 Clipping example: https://www.youtube.com/watch?
Page 22,"the goal of a sound event localization and detection method is to output all instances of the sound labels in the recording, its respective onset-offset times, and spatial locations in azimuth and elevation angles."
Page 23,Sense making from speech • Voice Activity Detection • Wake-word and Keyword Spotting • Speech Recognition • Speaker Diarization • Speech Emotion Recognition Page 23
Page 24,"Benchmark datasets Reference: T. Virtanen, M. Plumbley, and D. Ellis ."
Page 25,2025 National University of Singapore. All Rights Reserved Benchmark datasets Page 25 Reference: https://arxiv.org/pdf/[REDACTED_PHONE].pdf SINGA:PURA A Strong
Page 26,"a 100 Hz signal has 200 zero crossings 100 per second, whereas an unvoiced fricative can have 3000 zero crossing per second ."
Page 27,pyAudioAnalysis import short-termFeatures from the national university of Singapore . the function implements the long-term windowing process . this results to a sequence of feature vectors stored in
Page 28,fourier analysis F 0 = x=0 3 f(x)e i20x 4 = 2 + 3 + 4 + 4 = 13 F . eix = cos x
Page 29,"spectrogram index of windows FFT response Spectrogram: Time-Frequency 2D representation • Step 1, Windowing: Signal broken into (non)overlapping short-term windows • Step 2, FFT:"
Page 30,face masks may cause a reduction in speech intelligibility . there are small differences compared to the no-mask condition at lower frequencies .
Page 31,2025 National University of Singapore . All Rights Reserved Speech feature frames Page 31 of page 31 .
Page 32,Spectral centroid: center of gravity of the spectrum . it is calculated as the weighted mean of frequencies present in signal . x(u) represents the magnitude of frequency component at bin u .
Page 33,2025 National University of Singapore. All Rights Reserved Audio features: cepstral domain • Mel-Frequency Cepstre Coefficients (MFCC) • Compute fast Fourier transform (FFT
Page 34,"Mel scale relates perceived frequency, or pitch, to its actual measured frequency . humans are much better at discerning small changes in pitch at low frequencies than they are at high frequencies ."
Page 35,"Mel scale relates perceived frequency, or pitch, of a pure tone to its actual measured frequency . humans are less sensitive to small changes at higher frequencies ."
Page 36,delta and delta-delta features approximate first and second derivatives of f . features such as MFCC are typically appended by their delta and detla delta .
Page 37,speech vs music Page 37 high energy entropy mean: more spread out energy distribution low energy . rapid and irregular spectral changes low mfcc_3_std: smoother and more regular
Page 38,2025 National University of Singapore All Rights Reserved Use case: Audio events Page 38
Page 39,"2025 National University of Singapore. All Rights Reserved Overview of audio analytics system Reference: T. Virtanen, M. Plumbley, and D. Ellis ."
Page 40,"2025 National University of Singapore. All Rights Reserved Use case: Audio events Page 40 Each dot For each input audio sequence, we can obtain a sequence of feature values, each of which is calculated from a sliding window"
Page 41,2025 National University of Singapore. All Rights Reserved . Various audio feature extraction methods • Time-domain features .
Page 42,2025 National University of Singapore. All Rights Reserved Sound event detection . Objective: recognize what is happening in an audio signal and when it is happening .
Page 43,deep neural networks (DNNs) have become dominant in the field . neurons can be active at the same time indicating activity of multiple sound classes .
Page 44,sound event detection Page 44 Source: https://arxiv.org/pdf/[REDACTED_PHONE].pdf .
Page 45,sound event localization involves horizontal azimuth angle - vertical elevation angle . distance r from microphone that is recording sound scene .
Page 46,sound event localization Page 46 Source: https://www.aane.in/research/computational-audio-scene-analysis-casa/sound-event-localization-and-tracking .
Page 47,sound event localization Page 47 Source: https://www.aane.in/research/computational-audio-scene-analysis-casa/sound-event-localization-and-tracking .
Page 48,"technique used to identify, recognize and match audio signals based to their unique characteristics . Fingerprint: compact digital representation that can be stored and quickly compared against a database of know audio fingerprints ."
Page 49,2025 National University of Singapore. All Rights Reserved Audio fingerprinting . lowest (300 to 500Hz) and highest (2k to 5kHz) frequency often defined to focus on most relevant frequency ranges
Page 50,audio fingerprinting Locality sensitive hashing function: Place similar fingerprint values into the same buckets Page 50 Reference: https://www.pinecone.io/learn/series/faiss/local
Page 51,it detects whether a sound signal contains speech or not . it is a pre-processing algorithm for all other speech processing methods (e.g. speech coding and speech recognition)
Page 52,low-noise VAD = Trivial case Page 52 Reference: https://speechprocessingbook.aalto.fi/Recognition/Voice_activity_detection.html
Page 53,2025 National University of Singapore. All Rights Reserved VAD for noisy speech . not trivial to set energy thresholds for varying amounts of background noise.
Page 54,rule based VAD Page 54 Reference: https://speechprocessingbook.aalto.fi/Recognition/ Voice_activity_detection.html Suitable for limited resource devices .
Page 55,Detect non-speech as speech • False negatives: Miss actual speech • Objective of VAD implementation is application- dependent Page 55 .
Page 56,2025 National University of Singapore. All Rights Reserved Neural network based VAD Page 56 Reference: https://arxiv.org/pdf/[REDACTED_PHONE]
Page 57,Wake-word activates downstream systems (more complex tasks such as speech recognition and NLP) in voice-activated devices (e.g. Alexa) it generally runs on devices with limited resources .
Page 58,2025 National University of Singapore. All Rights Reserved Workshop Go to Assignments > RTAVS Day 3 Workshop Submission in Canvas Page 58 .
Page 59,2025 National University of Singapore. All Rights Reserved . Dr. Gary Leung Email: [REDACTED_EMAIL] Page 59 .
Overall Summary,AUDIO AND SPEECH ANALYTICS Dr. Gary Leung [REDACTED_EMAIL] Page 1 2025 National University of Singapore . All Rights Reserved Module objective Module: Audio and speech analytics Knowledge and understanding .
