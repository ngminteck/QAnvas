Page,Summary
Page 1," Dr. Gary Leung: ""Reverence"" is the name of a professor at the National University of Singapore . He is the author of the book, ""Reverevereverererererence"" and ""reverence"
Page 2, 2025 National University of Singapore . All Rights Reserved . National University Singapore is Singapore's largest university in Singapore's history . Singapore is one of the world's largest universities .
Page 3,"Module objective: Audio and speech analytics . Module objective: To understand the fundamentals of audio signal processing, feature extraction and representation ."
Page 4, The National University of Singapore's Day 1 program uses audio signal processing and speech recognition techniques . The project will focus on the audio-visual and voice-recognition capabilities of the National Institute of Singapore .
Page 5," A Python library for audio feature extraction, classification, segmentation and applications, PyAudioAnalysis, a Python library, is a useful tool for deep learning for audio ."
Page 6," Aims to extract high-level descriptions from raw audio signals using either signal analysis to extract features and representations, or machine learning (supervised or unsupervised) to discover patterns ."
Page 7," Emotion-aware dialogs, urban sound monitoring and watermelon pickers . How to pick a good watermelon? How to knock the melon  with your phone?"
Page 8, Sound (physics): A travelling vibration (wave) through a medium transfers energy (particle to particle) until ‚Äòperceived‚Äô  by our ears .
Page 9," The sampling rate is the sampling period (ùëáùë†) The sampling frequency is the attribute that describes the sampling process . For example: CD recordings 44.1 kHz, telephone 8 kHz, PC and smartphone 16 kHz"
Page 10," Sampling resolution (quantization) represents each real number, ùë•(ùëõ) Representing sequence of sequence of samples with an approximation from a finite set of discrete values ."
Page 11," Analog input and audio signals are used to communicate with computers in Singapore's National University of Singapore . The results are published at the age of 25,000 years of research ."
Page 12, Filtering Filtering A B is a form of formality . Filtering is the result of an analysis of the data collected by the National University of Singapore . The data was collected at the National Institute of Singapore.
Page 13, Filtering is the result of a study by the National University of Singapore . The study was published in the journal of the National Institute of Singapore.
Page 14, Filtering Sampling is a form of analysis of samples collected by the National University of Singapore . The results are published at the National Institute of Singapore's website .
Page 15," Filtering Sampling Quantizer was created by 2025 National University of Singapore . The Quantizer is called a ""Quantizer of Quality Assamination"""
Page 16, Filtering Sampling Quantizer: A B D E. (1-bit sign & 3-bit  magnitude) The Quantizer was created by 2025 National University of Singapore .
Page 17," Filtering Sampling Quantizer: A B D E G, a B C, a G, analog and a clock . The National University of Singapore has been awarded the title of the National Institute of Singapore‚Äôs Digital Sam"
Page 18, Filtering Sampling Quantizer (8) The National University of Singapore has been awarded the title of the National Institute of Singapore‚Äôs first published book . The book was published by the National University Singapore .
Page 19, Pulse-Code Modulation (PCM) is the basic method of digital representation of audio . 16-bit PCM is mostly used in speech processing . Each sample is represented with a fixed-point number in a computer .
Page 20," Popular audio file formats include Wav, MP3, FLAC and OGG . In speech processing, non-compressed PCM format is usually used for input ."
Page 21, The microphone quality and environmental quality of recording quality are monitored by the National University of Singapore . Too low: losing resolution or clipping (signal value exceeds maximum)
Page 22, Sense making from audio enables the prediction of urban sound tags for urban recordings from an urban acoustic sensor network . The National University of Singapore has published a paper on Sense Sense Making from audio .
Page 23," Sense making from speech: Voice Activity Detection, Wake-word and Keyword Spotting and Speech Emotion Recognition . Speech Language Recognition: Speech Language and Emotional Emotional Recognition for the first time ."
Page 24," Researchers from the National University of Singapore analysed sound scenes and events in a computer-generated dataset . The data was produced synthetically using a database called ""Rec"" and ""Syn"""
Page 25, National University of Singapore's PRA A Strongly- ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†Labelled Polyphonic . The PRA is a strongly-propelled polyphonic sound system . PRA was created by Singapore's National Institute of Singapore .
Page 26, Audio features: Time-domain features . Energy: Energy of the signal . Zero Crossing Rate: How often the signal changes . It measures smoothness of a signal is to  quantify the number of zero-crossing . A voice 
Page 27, The function implements the short-term windowing process . It returns a sequence of feature vectors stored in a numpy matrix .
Page 28," Fourier analysis of the Fourier Transform . Fourier coefficients: F(F(F) = 13, ‚àí2 + ùëñ , ‚àí1,  (2, 3, 4, 4), (Fourier"
Page 29, Spectrogram: Time-Frequency 2D representation. FFT: Fast Implementation of the Discrete Fourier Transform (DFT)
Page 30, Face masks may cause a reduction in speech intelligibility . Small differences compared to the no-mask condition at lower frequencies and significant decreases at higher frequencies .
Page 31, 2025 National University of Singapore. All Rights Reserved . National University Singapore . All rights to the Singaporean university . Use this article to help students with reading comprehension comprehension comprehension and vocabulary .
Page 32, Spectral centroid: Center of gravity of the spectrum . It is calculated as the weighted mean of frequencies present in signal .
Page 33, The Mel-Frequency Cepstral Coefficient (MFCC) is based on Mel-scale filter bank (see next slide) There are 13 MFCC values per segment .
Page 34," Mel scale relates perceived frequency, or pitch, of a pure tone to its actual measured frequency . Humans are much better at discerning small changes in pitch  at low frequencies than they are at high frequencies ."
Page 35," Mel scale relates perceived frequency, or pitch, of a pure tone to its actual measured frequency . Humans are highly sensitive to small changes at lower frequencies . Incorporating this scale makes our features match more closely what humans hear ."
Page 36, Features such as MFCC are typically appended by their delta and detla-delta features . The dimension of resultant features = 13 - 13 + 13 - 39 = 39 .
Page 37," High energy entropy mean: more spread out energy distribution . Low energy entropy means: more concentrated, predictable energy distribution. High mfcc_3_std: rapid and irregular  ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†spectral changes. Use case: Speech"
Page 38, Use this article to help students with reading comprehension and vocabulary . Use the weekly Newsquiz to test your knowledge of stories you saw on CNN iReport .
Page 39," Aims to analyze sound scenes and events using an analysis of sound scenes, events and events . The results are published at the National University of Singapore‚Äôs National Library ."
Page 40, The National University of Singapore uses a sliding window to display audio events . Each input or audio sequence is calculated from the input of an audio event to an audio sequence .
Page 41, What we have learnt: Audio signal representation. Various audio feature extraction methods. Time-domain features. Cepstral features. The University of Singapore. All Rights Reserved .
Page 42, Sound event detection aims to recognize what is happening in an audio signal and when it is happening . Objective: Recognition of what's happening in audio signal¬†and when it's happening .
Page 43, Deep neural networks (DNNs) have become dominant in the field of sound event detection . Early approaches:. Gaussian mixture models (GMM) and hidden Markov models (HMM)
Page 44, Sound event detection has been developed by the National University of Singapore . It is the first step in the development of sound event detection technology . The study was published on the Arxiviv.org/pdf/2107 .
Page 45, Sound event localization task: Identifying the location of a sound event with respect to the microphone that is recording the sound scene . Task: Identify the location  with respect  to the microphones that are recording the event .
Page 46, Sound event localization and tracking was created by the National University of Singapore . The sound event was created using sound-event-localization and tracking techniques .
Page 47, Sound event localization and tracking was created by the National University of Singapore . The sound event was created using sound-event-localization and tracking techniques .
Page 48," Audio fingerprinting is a technique used to identify, recognize and match audio signals based to their unique characteristics . Fingerprint: compact digital representation  that can be stored and quickly compared  against a database of know audio fingerprints . Applications:"
Page 49," Audio fingerprinting can detect spectral peaks (frequencies with high energy) Algorithms are often defined to focus on most relevant frequency ranges, avoid noise, and reduce feature size ."
Page 50, Audio fingerprinting function: Place similar fingerprint values into the same buckets . Place similar similar values in the same bucket . Use the hashing function to create a unique fingerprint .
Page 51, Voice Activity Detection (VAD) detects whether a sound signal contains speech or not . It is a pre-processing algorithm for all other speech processing methods (e.g. speech coding)
Page 52, Low-noise VAD = Trivial case. We can simply rely on energy thresholding . VAD is a low-noisy case. VAD means 'Trivial Case'
Page 53, VAD for noisy speech: Not trivial to set energy thresholds for varying amounts of background noise . VAD set energy threshold for varying background noise can be set at different levels of noise .
Page 54, Rule based VAD is based on a sequence of binary decisions to decide whether signal is speech or non-speech . Suitable for limited resource devices .
Page 55, False positives: Detect non-speech as speech. False negatives: Miss actual speech. VAD implementation is application-dependent .
Page 56, Neural network based VAD has been developed by the National University of Singapore . The VAD is based on a network of neural networks . The research was carried out at the National Institute of Singapore in Singapore .
Page 57, It activates downstream systems (more complex tasks such as  speech recognition and NLP) in voice-activated devices . Training requires several tens of thousands of utterances of  keywords (e.g.Alexa)
Page 58, RTAVS Day 3 Workshop: Submission in Canvas . Work on submission in canvas . Use this week's workshop to help students understand the workshop's objectives .
Page 59," Dr. Gary Leung: ""Thank you! Thank you! Dr. Leung"" Leung is the president of the National University of Singapore . Leung has been in Singapore for more than 20 years ."
Overall Summary," Aims to extract high-level descriptions from raw audio signals using signal analysis to extract features and representations, or machine learning (supervised or unsupervised) to discover patterns . Emotion-aware dialogs and urban sound"
