Page,Summary
Page 1,AUDIO AND SPEECH ANALYTICS Dr. Gary Leung [REDACTED_EMAIL] Page 1 .
Page 2,2025 National University of Singapore. All Rights Reserved • Day 1 • 1. Introduction • 2. Audio Signal Processing Basics • 3. Sound Event Detection and Localization • 4. Audio Fingerprinting • 5. Voice Activity Detect
Page 3,automatic speech recognition (ASR) or Speech-to-Text is a process to automatically convert speech into text . no understanding of the meaning yet .
Page 4,2025 National University of Singapore. All Rights Reserved History of Speech Recognition . speech recognition is a tradition of speech recognition .
Page 5,2025 National University of Singapore. All Rights Reserved History of Speech Recognition ([REDACTED_PHONE] .
Page 6,2025 National University of Singapore. All Rights Reserved in recent years . [REDACTED_PHONE] .
Page 7,2025 National University of Singapore. All Rights Reserved Deep Learning ASR – Recent Time Line .
Page 8,2025 National University of Singapore. All Rights Reserved Evolution of ASR Methods . 2025 .
Page 9,2025 National University of Singapore. All Rights Reserved Difficulties in Speech Recognition E.g. “Read” in English *Further Reading: Read vs Spontaneous Speech (http://
Page 10,2025 National University of Singapore. All Rights Reserved Feature Extraction . Feature extraction courtesy of the nasa .
Page 11,2025 National University of Singapore. All Rights Reserved Pronunications . Phoneme :
Page 12,2025 National University of Singapore. All Rights Reserved . traditional speech recognition framework is based on the traditional language recognition framework .
Page 13,2025 National University of Singapore. All Rights Reserved Traditional ASR System Evaluate how likely a certain word sequence corresponds to a sequence of sound units .
Page 14,2025 National University of Singapore. All Rights Reserved Traditional Acoustic Model . traditional Acoustic Model was developed by the national university of singapur .
Page 15,2025 National University of Singapore. All Rights Reserved HMM for Sentence for senate .
Page 16,2025 National University of Singapore. All Rights Reserved Language Model . Calculate P(W) from all the possibilities .
Page 17,language models are trained with text corpus to calculate likelihood of a word given previous word(s) 2025 National University of Singapore .
Page 18,Hybrid vs End-to-End (E2E) Modeling 2025 National University of Singapore.
Page 19,E2E models are much more compact than traditional hybrid models . can be deployed to devices with high accuracy and low latency .
Page 20,"E2E models achieve the state-of-the-art results in most benchmarks in terms of ASR accuracy . practical challenges such as streaming, latency, adaptation capability etc., have been also optimized in models ."
Page 21,2025 National University of Singapore . All Rights Reserved E2E Models 2019 .
Page 22,2025 National University of Singapore. All Rights Reserved End-to-End Speech Recognition • Connectionist Temporal Classification (CTC) method . convert the letter sequence into text .
Page 23,multiple modules are merged into one network for joint training . Sequence to Sequence model directly maps input acoustic feature sequence to the text result sequence .
Page 24,2025 National University of Singapore. All Rights Reserved CTC . [REDACTED_PHONE] .
Page 25,2025 National University of Singapore . All Rights Reserved CTC ASR Example Results . .
Page 26,2025 National University of Singapore. All Rights Reserved Attention-based End-to-end ASR.
Page 27,"LAS model: Listen, Attention and Spell . 2025 National University of Singapore. All Rights Reserved ."
Page 28,LAS model was created by the national university of Singapore in 2025 . all rights reserved . LAS models are currently being used in the u.s.
Page 29,full attention in AED may not be ideal to ASR because the decoder does not have access to future signals . RNN-T provides a natural way for streaming ASR .
Page 30,2025 National University of Singapore. All Rights Reserved RNN Transducer (RNN-T)
Page 31,RNN Transducer (RNN-T) 2025 National University of Singapore. All Rights Reserved .
Page 32,2025 National University of Singapore . All Rights Reserved E2E Models 2019 .
Page 33,Encoder is the Most Important Component of the National University of Singapore . 2025 - national university of singapur .
Page 34,2025 National University of Singapore. All Rights Reserved Encoder for RNN-T . .
Page 35,Transformer A good tutorial: https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452 .
Page 36,2025 National University of Singapore. All Rights Reserved Conformer - 2025 .
Page 37,"2025 National University of Singapore. All Rights Reserved How an ASR system is trained • Resources • Speech with text transcription, big enough to cover the language, should have word transcriptions • Pronunciation dictionary • Big text"
Page 38,"letter-based or byte pair encoding (BPE) based acoustic modeling is effective . Reasonably phonetic languages (e.g., English)"
Page 39,2025 National University of Singapore. All Rights Reserved Further Reading on Acoustic Modeling . Espnet: End-to-end speech processing .
Page 40,2025 National University of Singapore. All Rights Reserved Further Reading on N-gram Language Models . LM training with SRILM .
Page 41,"Dataset is divided into training, development and testing sets . Test on development set • Tune the system and repeat the process ."
Page 42,"Data Quality and Quantity • Diverse Data: • Ensure the dataset covers various accents, dialects, speaking rates, and noise levels . techniques like time-stretching, pitch-shifting, and adding background"
Page 43,2025 National University of Singapore. All Rights Reserved Accuracy Measure . ASR performance is usually judged by word Error Rate Character Eror Rate (CER) or SER may be used for some languages
Page 44,ASR performance is usually measured by Word Error Rate . this assumes that all errors are equal . Task-specific measures are sometimes used .
Page 45,"the model should be robust to different noise levels and types, especially for applications like voice assistants . different environments can affect acoustics, so it's essential to consider this during training ."
Page 46,2025 National University of Singapore. All Rights Reserved Considerations in ASR Deployment . Free text or limited text . Embedded system: Small system data size .
Page 47,"2025 National University of Singapore. All Rights Reserved Considerations in ASR Deployment . Distance • Near field: Smartphone, PC, etc ."
Page 48,2025 National University of Singapore. All Rights Reserved Considerations in ASR Deployment .
Page 49,2025 National University of Singapore. All Rights Reserved Speaker Recognition • To recognize persons from their voices • Input modes • Text dependent • Text independent • Decision modes • Identification (one-to-many matching)
Page 50,to find the speaker from a group of people . one to many matching . page 50 of the speaker's name .
Page 51,2025 National University of Singapore. All Rights Reserved Speaker Verification . to detect whether the voice belongs to the claimed speaker .
Page 52,adapted speaker recognition model is used for recognition . adapted model uses sample voice of target speaker to adapt to speaker's model .
Page 53,supervector + SVM • Build adapted speaker model first . use support vector machine (SVM) to do classification Page 53 .
Page 54,"i-Vector is a fixed-length low-dimensional representation of a variable-length speech utterance . a universal background model (UBM) that is used to collect sufficient statistics, a large projection"
Page 55,x-Vector • Embeddings are extracted from a feedforward deep neural network . long-term speaker characteristics are captured in the network by a temporal pooling layer that aggregates over the input speech
Page 56,2025 National University of Singapore. All Rights Reserved Accuracy Measure Page 56 .
Page 57,"a threshold should be set based on application . the speaker recognition system will be able to recognize speech . a few seconds voice for fast applications, or the longer speech for better accuracy."
Page 58,2025 National University of Singapore. All Rights Reserved Pros and Cons • Pros: • Identity can be recognized over telephone line . no special devices are needed .
Page 59,Authentication • Second and third factor authentication for remote banking • Access control • Personalized application • Detect speaker automatically Page 59 .
Page 60,"ALIZÉ • An opensourceplatform for speaker recognition . supports verification/identification, segmenting, etc."
Page 61,anti-spoofing to detect and counteract attempts where malicious actors try to deceive a speech or speaker recognition system using fake or manipulated voice recordings.
Page 62,"voice becomes a key biometric for authentication (e.g., phone banking) ensuring that the system isn't fooled by fake voices is crucial to prevent unauthorized access . devices like Amazon's Alexa"
Page 63,this involves recording a genuine user's voice and playing it back to deceive the system . it's one of the simplest yet effective attacks . modern TTS systems generate highly realistic voice outputs .
Page 64,systems can identify inconsistencies or patterns typical of synthesized or converted voices . deep learning models can capture intricate patterns and anomalies in the audio that might be indicative of spoofing .
Page 65,"a wide range of microphones and speakers can introduce variability into the audio signal, making it harder to establish a consistent baseline for genuine voice . this variability can mask the artifacts introduced by spoofing ."
Page 66,"2025, nvidia.com/deeplearning/nemo/user-guide/docs/en/main/asr/speaker_diarization/intro.html"
Page 67,"diarization helps in understanding the structure of the conversation . transcriptions become more informative and readable, especially in contexts like legal depositions or medical consultations where speaker identity is crucial ."
Page 68,"traditional methods struggle in such scenarios, and advanced models are required . Variability in Speech: a person's voice can vary due to emotions (e.g., anger, joy), health conditions, or environmental factors ."
Page 69,"non-speech segments (like silence or background noise) are filtered out, focusing the analysis only on speech segments . the continuous speech is divided into smaller, homogeneous segments, ideally such that each segment contains"
Page 70,NeMo Speaker Diarization Pipeline Page 70 Reference: https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/asr/speaker_
Page 71,the percentage of reference speaker speech that is not attributed to any speaker by the diarization system . a lower DER indicates better performance .
Page 72,xVector followed by PLDA . now can be handled well as a sub-task (as in OpenAI's Whisper model)
Page 73,"paralinguistic information: information beyond linguistic content of speech . speech addressee analysis (e.g., adult- vs. infant- directed speech)"
Page 74,paralinguistic speech processing is a typical processing pipeline . 2025 National University of Singapore .
Page 75,2025 National University of Singapore. All Rights Reserved Paralinguistic Speech Processing Page 75 - .
Page 76,"data containing sensitive metadata raises privacy concerns, restricting open distribution . data limitations restrict deep learning solutions for PSP tasks ."
Page 77,speech signals can reveal any type of personal information when transcribed . speech can convey nearly all types of private information . it is crucial to ensure its protection in contexts where privacy is a concern.
Page 78,"amazon sends 1,700 Alexa Voice Recordings to a random person . it was revealed that Google, apple and others are doing the same ."
Page 79,private information should be stored only as long as it is necessary . Pseudonymization: Strip away private and extra information .
Page 80,2025 National University of Singapore. All Rights Reserved Audio-visual Applications Page 80 Source: https://www.youtube.com/watch?v=rDggK77WAD0
Page 81,2025 National University of Singapore. All Rights Reserved Audio-visual Applications Page 81 Reference: https://arxiv.org/pdf/[REDACTED_PHONE] https://github.com/J
Page 82,2025 National University of Singapore. All Rights Reserved Audio-visual Captioning Page 82 Reference: https://arxiv.org/pdf/[REDACTED_PHONE] https://github.com
Page 83,2025 National University of Singapore. All Rights Reserved Audio-visual Applications Page 83 Reference: https://arxiv.org/pdf/[REDACTED_PHONE]
Page 84,2025 National University of Singapore. All Rights Reserved Audio-visual Applications Page 84 Reference: https://arxiv.org/pdf/[REDACTED_PHONE]
Page 85,2025 National University of Singapore. All Rights Reserved Workshop Go to Assignments > RTAVS Day 4 Workshop Submission in Canvas Page 85 .
Page 86,2025 National University of Singapore. All Rights Reserved . Dr. Gary Leung Email: [REDACTED_EMAIL] Page 86 .
Overall Summary,all Rights Reserved AUDIO AND SPEECH ANALYTICS Dr. Gary Leung [REDACTED_EMAIL] Page 1 2025 National University of Singapore . All rights Reserved • Day 1 • 1. Introduction • 2. Audio Signal Processing Basics • 3. Sound Event Detection and Localization • 4. Audio Fingerprinting • 6. Wake-word and Keyword Spotting • Day 2 • 7. Speech Recognition • 8. Speaker Recognition • 9. Speaker Diarization • 11. Paralinguistic Speech Processing • 12. Security and Privacy •
