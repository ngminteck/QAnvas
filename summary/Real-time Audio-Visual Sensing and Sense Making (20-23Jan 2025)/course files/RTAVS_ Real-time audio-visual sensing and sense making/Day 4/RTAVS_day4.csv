Page,Summary
Page 1,dr. Gary Leung Email: [REDACTED_EMAIL] Speech Analytics II .
Page 2,Topic 5: Emerging Aadvanced Speech Processing . topic 5: emerging aadvananced speech processing .
Page 3,SPEECH FOUNDATION MODLES 3 MODELS PART 1 MODLES PART 2 MODLES 1 MODEL PART 1.
Page 4,supervised learning: No human labels needed. Easy to build databases . self-supervised learning: Use information from input data as the label to learn representations.
Page 5,downstream task uses the learned representation from a pre-trained model (frozen) or fine-tunes the model using supervised data 5 .
Page 6,wav2Vec 2.0: a framework for self-supervised learning of speech representation . aims to maximize the similarity between contextual representation and quantized input features .
Page 7,fine-tuned Wav2Vec 2.0 model architecture achieved 8.2%WER . average performance on low resource languages .
Page 8,many speech representations are created by self-supervised learning . they can be used in many downstream applications . source: https://github.com/s3prl/8 .
Page 9,the most comprehensive library for pre-trained models . a fine-tuned Wav2vec 2.0/HuBERT benchmark 9 .
Page 10,"self learned representation and fine-tuning together can improve accuracy for low resource speech recognition . it showed good performance on many downstream tasks like speaker recognition, emotion recognition, speech separation ."
Page 11,PART 2. MULTI-TALKER SPEECH RECOGNITION 11 of the PART 2 .
Page 12,E2E multi-talker models have high accuracy in single-speaker applications . solutions are difficult to achieve . satisfactory accuracy in scenarios with multiple speakers talking at same time .
Page 13,"Kanda et al. ""Streaming Speaker-Attributed ASR with Token-Level Speaker Embeddings"""
Page 14,PART 3 SPEECH-TO-SPEECH TRANSLATION 14 - PART 1 - STANDARD TRANSLATORY PART 2 .
Page 15,"cost is very high because machine translation (MT) needs to be called multiple times . read-write operation is interleaving, not flexible ."
Page 16,"ST Xue et al. ""Large-Scale Streaming End-to-End Speech Translation with Neural Transducers"" in proc. interspeech ."
Page 17,Accelerating Digital ExcellenceCopyright National University of Singapore [REDACTED_PHONE] t ea Frames Labels 7 8 m 9 10 11 Flexible RNN-T Path 17
Page 18,multilingual data pooled together to train a streaming model to perform both ST and ASR functions . the model is totally weakly supervised without using any human labeled parallel corpus .
Page 19,PART 4 SPEECH LARGE LANGUAGE MODELS 19 . PART4 .
Page 20,speech LLM can be converted to an automatic speech recognition system . LLaMA-7B can outperform monolingual baselines by 18% and perform multilingual speech recognition .
Page 21,"Accelerating Digital ExcellenceCopyright National University of Singapore 1. Speech LLM 21 Prompting Large Language Models with Speech Recognition Abilities, Yassir Fathullah et al."
Page 22,"speech LLM 22 Prompting Large Language Models with Speech Recognition Abilities, Yassir Fathullah et al."
Page 23,audioPaLM fuses text-based and speech-based language models into a unified multimodal architecture . resulting model significantly outperforms existing systems for speech translation tasks and has the ability to perform zero-shot speech
Page 24,Accelerating Digital ExcellenceCopyright National University of Singapore 2 . audioPaLM 24 is the latest in a generation of digital excellence .
Page 25,Topic 6: Spoken Dialogue Processing
Page 26,PART 1 INTRODUCTION 26 - PARTI 1 - INTRODUCTIONS .
Page 27,Accelerating Digital ExcellenceCopyright National University of Singapore Examples of Spoken Dialogue • Speech Assistant: Amazon Echo • Google Home • Siri • robots • Social robot • Navigation and information 27.
Page 28,speech recognizer: to listen to human voice . to understand the language and respond Spoken Dialogue System (SDS)
Page 29,CONSIDERATIONS IN BUILDING SDS 29 . PART 2 CONSIDÉRATIONS .
Page 30,"is your system domain-specific (e.g., booking flights) or open- domain? What tasks should the system perform? information retrieval, transaction processing, or simple chit-chat ."
Page 31,"automatic speech recognition (ASR): This converts spoken language into text . consider factors like accuracy, real-time processing, and noise handling ."
Page 32,text-to-speech (TTS): Convert system responses back into spoken language . choose a voice that fits the application's context .
Page 33,the system responds to unrecognized or misunderstood inputs . feedback: Providing auditory cues to indicate the system is listening or processing .
Page 34,"usability testing: • Engage real users to test the system's functionality and UX . Performance Metrics: • Measure ASR accuracy, NLU accuracy, response time, etc."
Page 35,Ensure the system can handle the expected number of users . how will the SDS integrate with other systems or databases?
Page 36,"multimodality: consider if the system will integrate other modes of interaction, like touch or visual displays . have a strategy for when the system cannot understand or process a user's request ."
Page 37,PART 3 DIALOG FLOW 37 - 37 . PART3 - PART 3. PART 2. PART 1.
Page 38,"Google Cloud contains quite a lot of products such as NLP , Computer Vision, Machine Learning, Big data, etc."
Page 39,a module to handle the conversation with end user . the module can categorize end-user intentions for each conversation turn .
Page 40,Dialogflow supports speech input and output . both input and input can be configured to use text or speech . Streaming: pass the recording little by little .
Page 41,PART 4: WORK WITH DIALOGFLOW 41 . PART 3: PART 4. PART 1.4 .
Page 42,"to build a dialog demo that supports booking a meeting room, the required information includes: Date, Time, Duration, Location, Room Name (A, B, C)"
Page 43,Dialogflow.cloud.google.com • Create an agent • Project automatically created . keep a record of the Project ID .
Page 44,if we would like to create an intent from scratch (instead of importing) please refer to https://cloud.google.com/dialogflow/cx/docs/quick/build-a
Page 45,"Create service account key: https://console.cloud.google.com/apis/credentials/serviceaccountkey . Select the service account name, enter a name, click Create and continue ."
Page 46,speech output to file: test_tts.py https://cloud.google.com/dialogflow/es/docs/how/detect-intent-stream 46 .
Page 47,CHATGPT AND OPENAI API 47 is a PART 5 PART 7 - PART 4 .
Page 48,ChatGPT API launched by openAI on 30 Nov 2022 . can perform many text generation tasks through multi- round conversations .
Page 49,Accelerating Digital ExcellenceCopyright National University of Singapore ChatGPT – Training process 49 . .
Page 50,Accelerating Digital ExcellenceCopyright National University of Singapore ChatGPT’s Voice and Image Capability OpenAI announced on 25 Sep 2023 .
Page 51,chatGPT's new voice technology opens doors to many creative and accessibility-focused applications . the new technology is capable of crafting realistic synthetic voices from just a few seconds of real speech .
Page 52,key concepts: • Prompt: user input • Completion: text that matches the user input. • Token: words or chunks of characters .
Page 53,Text Completion: multiple tasks; chat completion . image generation: to convert text into vector representation . speech recognition: speech recognition and translation .
Page 54,"Obtain an API key: 1. Log into http://openai.com 2. Click on “Personal”, then click “API keys” 3. Click “Create new secret key” and save the generated key to a"
Page 55,"Text Completion API: • Generation: story ideas, business plans, marketing slogans, etc. • Conversation: To chat with humans . Inserting text: providing both prefix and instruction, it will edit text."
Page 56,openAI API - PlayGround is a text box where you can submit a prompt to generate a completion .
Page 57,"text import openai.api_key = “xxxxx” prompt = (f""Write an article on ChatGPT API"") completions = openais.Completion.create( engine=""text-da"
Page 58,chatGPT is powered by gpt-3.5-turbo . Tutor in a range of subjects . Simulate characters for video games .
Page 59,"openai.ChatCompletion.create: ""system"", ""content"": ""who won the world series in 2020?"", ""role: ""assistant,"" ""content,"" ""where was it played"
Page 60,"speech-to-text processing import openai audio_file= open(""/path/to/file/audio.mp3"", ""rb"") transcript ."
Page 61,facebook.com/iss.nus instagram.com . Thank you for visiting www.iss-nus.edu .
Overall Summary,"a framework for self-supervised learning of speech representations (2020), coRR 6 Accelerating Digital ExcellenceCopyright National University of Singapore Wav2Vec 2.0 • A method to train speech representation. • Good performance on low resource languages • Achieved 8.2%WER when fine-tuned with 10 minutes data ."
