Page,Summary
Page 1,S-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 1 SPATIAL REASONING VISION-BASED LOCALIZATION Dr TIAN
Page 2,"S-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 2 Vision-based localization Visual odometry Reference: ECCV 2022 Tutorial, Self-"
Page 3,S-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 3 Agenda .
Page 4,"s-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 4 Positioning solution Objective of localization • Refer to environment (where am I?), useful for navigation"
Page 5,the technique is called visual odometry . it is the process of determining the position and orientation of a robot by analyzing the camera images .
Page 6,s-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 6 Visual odometry Assumptions/requirement of visual . o
Page 7,two stereo cameras + LiDAR • 6 hours recording at 10 frames per second Stereo image sequence Timestamp Stereo camera calibration Ground truth camera poses (used in performance evaluation) XX direction Right YY direction Up ZZ direction Forward
Page 8,the relationship between camera reference system to image reference system Pinhole camera model Q3 is changed (camera movement). Extrinsic matrix Q2 .
Page 9,S-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 9 Extrinsic matrix Translation only Rotation only: Around zz axis XXc
Page 10,"the image reference system xx, yy 1 depends on camera model focal length ff . theorem xxcc is a triangle similarity ."
Page 11,"the intrinsic matrix could be KK = [REDACTED_PHONE] Suppose for the CMOS/CCD sensor, each pixel has a physical size of ddxx, ddyy, the image plane"
Page 12,"s-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 12 Summary of visual odometry • Step 1: Given two consecutive frames, find the pair of"
Page 13,S-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 13 Agenda • Visual odometry • Visual place recognition pipeline • Feature extraction .
Page 14,s-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 14 Visual place recognition: Motivation Global localization problem • Perform localization via the pre-collected gallery
Page 15,s-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 15 Image retrieval: Have I seen this image before? Which images in my database look similar to it?
Page 16,s-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 16 Visual place recognition: Motivation • An accurate camera pose estimate is necessary for building a map of the environment
Page 17,s-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 17 Visual place recognition: Intuition .
Page 18,S-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 18 Visual place recognition: Challenge Reference: A survey on Visual-Based Localization: On the benefit of heterogen
Page 19,"video Google was proposed in 2003 [2], marking the beginning of the BoW model . CNN-based methods began to gradually take over, such as the fine-tuned CNN model for generic instance retrieval ."
Page 20,"s-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 20 Visual place recognition: Major dataset Dataset # image # query Content Oxford5k 5,062 55 Building"
Page 21,page 21 performance metric Query image (single input) Returned results (ranked) from the gallery . how to evaluate the system performance based on multiple queries?
Page 22,performance metric K Supposed to be 5 for this query image . average precision = average precision (for a single query)
Page 23,"Feature encoding (dictionary) Feature extraction Feature indexing (search) Reference: L. Zheng, Y. Yang, Q. Tian, SIFT Meet CNN: A Decade Survey of Instance"
Page 24,"Feature extraction Features Remark Hand- crafted Global Image feature Color histogram Vision Systems course Local Patch feature LBP, HoG Vision Systems courses Point-based patch feature SIFT Previous day’s course ORB Following slides Learne"
Page 25,pixel pp (intensity value IIpp) in the image as an interest point or not based on its neighboring pixels . if there exists a set of nn continuous pixels in the circle (of
Page 26,S-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 26 ORB: Oriented FAST and rotated BRIEF Reference: https://medium.
Page 27,LIFT: Learned invariant feature transform Model training . patches P1 and P2 (blue) are different views of the same physical point . P4 (red) contains no distinctive feature points .
Page 28,the final loss is the sum of two intermediate losses . we use pairs of synthetically warped images including (a) pseudo-ground truth interest point locations and (b) the ground truth correspondence from a randomly generated homography that
Page 29,s-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 29 Pre-trained CNN: Neural code • Use of feature activation from the top layers of CNN
Page 30,"kk is the number of feature channels Reference: G. Tolias, et al., Particular object retrieval with integral max-pooling of CNN activations, ICLR 2016, https://arxiv"
Page 31,we show the top-left region of each scale (gray colored region) and its neighbouring regions towards each direction (dashed borders) the cross indicates the region centre . regional feature vector: Fixed multi-scale overlapping spatial
Page 32,s-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 32 Pre-trained CNN: Others Many other methods that use activation maps obtained from the pre-t
Page 33,Contrastive loss has two branches with shared parameters . it computes the similarity distance between the output descriptors of the branches . triplet loss function computes distance between positive and negative pairs .
Page 34,"Feature encoding (dictionary) Feature extraction Feature indexing (search) Reference: L. Zheng, Y. Yang, Q. Tian, SIFT Meet CNN: A Decade Survey of Instance"
Page 35,s-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 35 Intuition: Part model Model • Object as a set of parts • Relative
Page 36,"CC = 0,1,2,3,4 computed from the following samples . each sample is encoded, all such vectors are pooled into one vector ."
Page 37,S-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 37 Intuition: keywords in document Document representation: Frequencies of keywords from a dictionary.
Page 38,"Feature extraction: For each image, extract feature descriptor at each keypoint . Generate histogram for each image by combining frequencies of “visual words”"
Page 39,vvkk = exp xxiicckk 2 kk′ exp xiii kckk′ 2 x iicckki . each vector has DD
Page 40,vvkk = ii=c NN exp xxii cckk′ exp wwkk TTxxiI + bbkk kk′ exp and TT
Page 41,patch-NetVLAD takes as input an initial list of most likely reference matches to a query image . it computes new patch-level descriptors at multiple scales to perform local cross-matching of these de
Page 42,contextual patch-NetVLAD: Context-aware patch feature descriptor aggregates features from each patch’s surrounding neighborhood . context-driven weighting rules assign higher weights to patches that are less similar to
Page 43,"s-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore . qq = [5, 1, 1, 0] Histogram Intersection HHc = 10, 0, 0, 0, 100,"
Page 44,"Feature encoding (dictionary) Feature extraction Feature indexing (search) Reference: L. Zheng, Y. Yang, Q. Tian, SIFT Meet CNN: A Decade Survey of Instance"
Page 45,S-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 45 Vocabulary trees (1): Hierarchical clustering for large vocabularies Reference: N
Page 46,S-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore . All Rights Reserved Page 46 Vocabulary trees (2): Inverted file index Word1 Word2 Word3 Word1 word2
Page 47,page 47 Vocabulary tree reference: Nister and Stewenius . CVPR 2006 indexing: Filling the tree .
Page 48,"S-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 48 Vocabulary tree reference: Nister and Stewenius, Scalable Recognition with a Vocab"
Page 49,"S-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 49 Vocabulary tree Reference: Nister and Stewenius, Scalable Recognition with a Vocab"
Page 50,"S-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 50 Vocabulary tree Reference: Nister and Stewenius, Scalable Recognition with a Vocab"
Page 51,S-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 51 Workshop . Objective: Perform image-based place recognition .
Page 52,S-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Page 52 Thank you!
Overall Summary,"S-SRSD/Spatial reasoning/V[REDACTED_PHONE] National University of Singapore . All Rights Reserved Page 2 Vision-based localization Visual odometry Reference: ECCV 2022 Tutorial, Self-Supervision on Wheels: Advances in self-supervised learning from Autonomous Driving Data ."
