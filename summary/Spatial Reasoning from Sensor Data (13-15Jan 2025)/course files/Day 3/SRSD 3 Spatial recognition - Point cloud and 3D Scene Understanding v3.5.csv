Page,Summary
Page 1,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved SPATIAL RECOGNITION POINT CLOUD & 3D SCENE UNDERSTAND Dr
Page 2,"Xavier Xie Sr. Lecturer, Senior Scientist and Tech Lead Ph.D, CEng MIMechE, PMP®, CSM® Email: [REDACTED_EMAIL] HP:"
Page 3,"3D data refers to information structured in three dimensions . each data point is defined by three coordinates (x, y, z) enabling the representation of spatial relationships and properties not possible in 2D ."
Page 4,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Common 2D Data Page 4 2D image Spreadsheet Tables Heatmap Matrix Map .
Page 5,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Common 3D Data Page 5 Terrain CAD MRI Point Cloud Molecular Structure Weather Simulation .
Page 6,"3D Data Representation Limited to two dimensions Inherently more complex with three dimensions Visualization Occlusion, limited perspectives Complex spatial relationships, viewpoints Data Complexity Generally less complex Higher complexity due to additional dimension Processing Efficiency Typically computational"
Page 7,"S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore . All rights reserved techniques for analysis Page 7 Aspect Techniques for 2D data techniques for 3D Data Image Processing Filtering,"
Page 8,3D Data Sensing Page 8 Structure Light 2.5D Depth Camera Photogrammetry Sonar and Ultrasonic SensorsLiDAR 3D ToF Camera .
Page 9,s-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved 3D Data Sensing Page 9 . waymo Apple Vision Pro Robotic Grasping:
Page 10,"3D Printing: Rapid prototyping and personalized items by layer by layer through additive manufacturing . medical diagnostics: Diagnosis, treatment planning and surgery, visualize and analyze anatomical structures or organs."
Page 11,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Rasterized form (regular grids) Multi-view images A 2D projected view Depth image A
Page 12,"3D printing, CAD OBJ Stores geometry, textures, and surface properties . 3D scanning, research GLTF Efficient format for real-time rendering . web-based 3D apps, AR COLL"
Page 13,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Workshop 3A Page 13 • Find SRSD Day 3 worksheet Materials • Read materials for the two solutions Fine Pose
Page 14,"NN can effectively cover Feature Extraction, Point Cloud Representation, Model Inference . powerful tool for automated and end-to-end point cloud analysis ."
Page 15,"Feature-Based Registration: Aligns point clouds using distinctive features and key points . Detects and matches features (e.g., Fast Point Feature Histogram - FPFH, Scale-Invari"
Page 16,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore . All Rights Reserved PCS Demo - Global Registration Page 16 .
Page 17,iterative closest point (ICP) is a widely used algorithm for aligning two point clouds . it finds the rigid transformation (rotation and translation) that best aligns the source point cloud to the target .
Page 18,"initialization: start with an initial guess for the transformation TT (rotation and translation) if no prior information is available, use the identity transformation as the starting point . e.g. closest point association: For"
Page 19,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Strengths and Limitations Page 19 Strengths: • Simple and widely applicable. • Effective for rigid transformations; •
Page 20,"Python Open3D is a versatile library offering efficient 3D data structures, processing algorithms, scene reconstruction, surface alignment, high-quality visualization, machine learning integration, GPU acceleration, and support for C++ and Python ."
Page 21,"S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Hands-on Practise Page 21 View 1 View 2 Using Point-to-Point ICP,"
Page 22,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore . Evolution Map - ML for PC Page 22 .
Page 23,3D data machine learning reference: https://github.com/philastotle/pointnet-tutorial Page 23 .
Page 24,"RGB-D Object Dataset, http://rgbd- dataset.cs.washington.edu . NTU RGB+D dataset contains 60 action classes and 56,880 video samples ."
Page 25,"RGB-D datasets Page 25 Dataset Description Content Format Website ModelNet CAD models for classification tasks 40 categories (e.g., chairs, cars, etc.) Meshes, voxels ModelNet ShapeNet Rich"
Page 26,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved 3D Scene Understanding Page 26 Reference: https://navoshta.com/kitti-lid
Page 27,"multi-sensor and multi-modality approaches are crucial to improving the accuracy and robustness of 3D scene understanding . e.g., RGB + D, RGBD + LiDAR, Thermal + Visual etc."
Page 28,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Key Components Page 28 .
Page 29,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Building & Construction Page 29 .
Page 30,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Auto Tool Path Generation Page 30.
Page 31,S-SRSD/Spatial recognition/V[REDACTED_PHONE] . AV Scene Understanding Page 31 .
Page 32,s-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Depth can help us 1.
Page 33,Depth information encodes geometric cues necessary to separate objects instances . s-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore .
Page 34,s-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Depth can help us Camera Field of Views (FOV)
Page 35,image classification page 35 Question: Suppose that we have downloaded a pre-trained CNN classification model that is trained using the RGB only . Stack the depth image as the additional 4-th channel of the input tensor
Page 36,RGB-D data is a geocentric embedding that converts a depth image into a three-channel map . the DD data encodes properties of geocentric pose that emphasize complementary discontinuities .
Page 37,"RGB-D data: Object detection We need to build a model that can output •Box label (one-hot vector, a classification problem) x, yy, ww, h x x"
Page 38,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved RGB-D data: Object detection Conventional approach .
Page 39,s-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved RGB-D data: Object detection Reference: Exploring RGB+Depth Fusion for Real-Time
Page 40,"the RGB image and the depth map are processed separately, e.g. using two different networks, to produce various types of features . they are then fused together either by concatenation or by convolutional networks ."
Page 41,"ccEEEE means a parameter-free correlation layer, which performs multiplicative comparisons . geometrical features are 3-channel features calculated from the 1-channel depth image ."
Page 42,deep learning fusion scheme fuses features extracted from multiple representations of input . fusion pipeline uses element-wise mean pooling operations .
Page 43,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved RGB-D data: Segmentation Page 43 Image fusion Output fusion Reference: A brief survey on RGB
Page 44,"point cloud data can be represented as a numpy array with NN rows and 3 columns . each row corresponds to a single point, which is represented using at least 3 values for its position in space (xx,"
Page 45,"S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Point cloud Page 45 KITTI dataset: Cars (blue), trams (red), and cyclists ("
Page 46,"Point cloud data augmentation Page 46 Reference: Improving 3D Object Detection through Progressive Population Based Augmentation, ECCV 2020, https://arxiv.org/abs/[REDACTED_PH"
Page 47,s-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Point cloud data representation Page 47 .
Page 48,"230K human-labeled 3D object annotations in 39,179 LiDAR point cloud frames . corresponding frontal-facing RGB images captured at different times (day, night) and weathers ."
Page 49,"3D object detection in autonomous driving scenarios . 3D Object Detection for Autonomous Driving: A Comprehensive Survey, IJCV, 2023 ."
Page 50,"""Deep Learning for 3D Point Clouds: A Survey,"" IEEE Trans. on Pattern Analysis and Machine Intelligence, Vol. 43, No. 12, Dec. 2021."
Page 51,"ICCV 2015, https://arxiv.org/abs/[REDACTED_PHONE] VoxNet D. Maturana, et al., ""Complex-YOLO: An"
Page 52,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore . first CNN: Extract image features from individual view . second CNN: extract shape features from pooled image .
Page 53,"IROS 2015, https://dimatura.net/research/voxnet/v[REDACTED_PHONE] National University of Singapore ."
Page 54,"complex YOLO Page 54 The bird’s eye view representation is encoded by height, intensity and density . height: the maximum height of the points in the cell ."
Page 55,"S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore . All Rights Reserved PointPillars Page 55 Reference: A. Lang, et al."
Page 56,"PointNet uses a shared multi-layer perceptron (MLP) to map each of the cc points from 3D (xx, yy, zz) to 64 dimensions (64-64 nodes)"
Page 57,"point cloud classification with PointNet, created on may 2020 . based on a set of points, the result is a table problem statement ."
Page 58,"PointNet (2) Page 58 cc c 0.224, 0.325, [REDACTED_PHONE], 0.262, [redACTED] -0.024 . Feature extraction (to be designed"
Page 59,"cc c 0.224, 0.325, [REDACTED_PHONE], 0.206, 0.554 ...,, MLPMax pooling Input point cloud data Classification result: Table • A M"
Page 60,"PointNet (4) Page 60 cc c 0.224, 0.325, [REDACTED_PHONE], 0.206, 0.554 ...,,..., MLP Max pooling Input point cloud data"
Page 61,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Point-based object detection Page 61 Reference: 3D Object Detection for Autonomous Driving:
Page 62,"S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore . All Rights Reserved PointRCNN Page 62 Reference: S. Shi, et al."
Page 63,Pointformer consists of three parts: a Local Transformer to model interactions in the local region . a Global Transformer to capture context-aware representations at the scene level .
Page 64,"the core component, the Point Transformer Layer, dynamically computes attention based on spatial positions and feature similarities, enabling adaptive feature aggregation . the architecture employs a hierarchical structure with downsampling for"
Page 65,"Point Transformers Page 65 Their Point Transformer model achieves state-of-the-art results across multiple benchmarks, including a mean Intersection over Union (mIoU) of 70.4% on Area 5 of the S3"
Page 66,"Generative AI for Scene Understanding Page 66 refers to models and techniques that learn patterns from data to generate new, plausible outputs . these outputs may include: •Text (e.g., GPT models)"
Page 67,"the diagram represents a pipeline for 3D scene representation and rendering using methods such as neural networks, radiance fields, signed distance fields (SDFs) and rendering techniques like volume rendering and sphere tracing ."
Page 68,"SV3D rapidly generates high-quality 3D assets from a single image in 0.5 seconds, serving industries like gaming, VR, retail, architecture, and design ."
Page 69,s-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore . the triplane transformer then uses the sampled point cloud and image features to produce high- resolution triplane features .
Page 70,s-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Case Study - Robotic Manipulation in Industrial Environments Page 70 .
Page 71,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All rights Reserved Discussion 3B Page 71 .
Page 72,Workshop 3B Page 72 Point cloud classification using PointNet Reference: https://datascienceub.medium.com/pointnet-implementation-explained-visually-c7e[REDACTED_PH
Page 73,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Workshop Page 73 Label 8 Predict 4 Workshop on design and build a spatial reasoning system: Point cloud classification using
Page 74,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved .
Page 75,S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore. All Rights Reserved Appendix Page 75.
Page 76,Feature-Based Registration Aligns point clouds using distinctive features and keypoints . iterative closest point (ICP) Iteratively minimizes distances between corresponding points .
Overall Summary,"S-SRSD/Spatial recognition/V[REDACTED_PHONE] National University of Singapore . All Rights Reserved SPATIAL RECOGNITION POINT CLOUD & 3D SCENE UNDERSTAND Dr. Xavier Xie, Senior Lecturer & Consultant ."
