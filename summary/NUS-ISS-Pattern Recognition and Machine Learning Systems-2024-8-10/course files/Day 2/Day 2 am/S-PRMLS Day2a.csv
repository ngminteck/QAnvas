Page,Summary
Page 1,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved 1 PATTERN RECOGNITION AND MACHINE LEARNING SYSTEM
Page 2,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved 2 2.1 Neural Network Models and Designs.
Page 3,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore . All Rights Reserved 3 Topics .
Page 4,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved 4 Radial Basis Function Networks .
Page 5,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved 5 Architecture of RBF Networks • Nodes: • Each node in the input-
Page 6,j-th basis function (kernel) gives the same activation value for all inputs within the same radial distance of its kernel centre cj . i-th node in hidden layer is calculated by
Page 7,training requires two parameters (ci and i ) to be found for each kernel node . training is performed in two stages: finding centre and smoothing parameter values for the hidden nodes (supervised learning)
Page 8,"ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore . if the number of input samples xi is small, set kernel centre ci = x"
Page 9,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved 9 RBF Network Learning (cont.) Learning in output layer . Adjust weights
Page 10,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved 10 A Simple Example of RBF Learning • Build a RBF network with four hidden units
Page 11,"ci is the weight vector of hidden unit Ci (i = 1, 2, 3, 4), x is an input vector (the simple function requires NO smoothing parameter). the activation of output node is a linear combination of the"
Page 12,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved .
Page 13,the two-stage training process of RBF permits the use of unlabeled training data (unsupervised training methods) while creating kernel nodes . only a relatively small number of labelled data will be needed to find the output
Page 14,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore . the GRNN architecture consists of an input-layer .
Page 15,the input-layer distributes input patterns to the pattern-layer through adjustable weights . each pattern node computes the distance between the input vector and their connection weight vector values .
Page 16,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved 16 Activation of general Regression NN . we can obtain where Di 2 =
Page 17,"in the pattern layer, a new neuron is created for each exemplar pattern (or cluster centre) the weight values are set equal to the exemplars or cluster centres (centroid values)"
Page 18,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] . small values of give narrow peaked surfaces that fit well .
Page 19,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] . a form of self-growing net with one pattern unit created for each new training pattern or cluster centre .
Page 20,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore . a GRNN has the ability to work with sparse data and in real-time environments
Page 21,simulations were carried out to see how well different ANN architectures could model the dynamics of a fighter aircraft for two highly nonlinear manoeuvres: low angles of attack dynamics and deep-stalls .
Page 22,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved 22 An Example of GRNN Application (cont.) — Adaptive Control
Page 23,"ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore . performance comparison was based on learning speed, modelling precision, network flexibility, and complexity ."
Page 24,"the performance of three networks (six networks have been done, but only three are given here) was satisfactory, but the GRNN was best (compare the errors for angle of attack and pitch rate, E a and Eq"
Page 25,"ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved 25 Self-Organizing Map (SOM, Kohonen) Network ."
Page 26,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved 26 Competitive Network Operation • Signals feed forward from input nodes and feed lateral among
Page 27,Feature mapping converts patterns of arbitrary dimension (the pattern space) into the response of one- or two-dimensional arrays of neurons . a one-dimensional network is a single layer of units arranged in a
Page 28,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved.
Page 29,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore . x is fully distributed to each node in the discrete lattice network .
Page 30,the winning output unit is the one with the smallest dissimilarity measure (or largest similarity measure) among all weight vectors wi and input vector x . repeat steps 2 through 4 until the network weights stabilize .
Page 31,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore . Smooth functions such as Gaussian or other types may be used .
Page 32,weight vectors of neurons in the neighborhood of the winning neuron s are shifted towards the input vector value . those nearer to s have weights shifted more and those farther away shifted less .
Page 33,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved 33 Simulations of SOM .
Page 34,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved 34 Simulations of SOM (cont.) input data uniformly distributed within [0
Page 35,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved 35 Advantages of SOM • It provides a method of data compression .
Page 36,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore . one-dimensional SOM networks have been used to successfully solve optimization problems .
Page 37,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved 37 Application Examples of SOM (cont.)
Page 38,"ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] . Workshop: RBF, GRNN & SOM ."
Page 39,ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved 39 Workshop: RBF -Weka Continue from the Day 1 Workshop on using
Page 40,40 workshop: GRNN & SOM – Python / Neupy . make sure you understand how the NN models are built . save notes as markdown in the notebook .
Overall Summary,"ATAS-PRMLSDay2a.pptV[REDACTED_PHONE] National University of Singapore. All Rights Reserved 1 PATTERN RECOGNITION AND MACHINE LEARNING SYSTEMS DAY 2A Dr Zhu Fangming NUS-ISS [REDACTED_EMAIL] not be reproduced in any form or by any means, without the written permission of ISS, NUS ."
